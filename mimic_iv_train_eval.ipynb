{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t5Vxuf0e7j6o",
        "outputId": "d92599aa-ccc1-4467-85de-844b21274ffb"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "import pickle\n",
        "import random\n",
        "import numpy as np\n",
        "from math import isfinite\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from tqdm import tqdm\n",
        "from transformers import AutoTokenizer, GPT2Config, GPT2LMHeadModel\n",
        "\n",
        "# ---------------- CONFIG ----------------\n",
        "DATA_DIR = \"/content/drive/MyDrive/labtop2/v1\"  # <-- adjust\n",
        "MAX_LEN = 1024            # must be <= preprocessor max_len\n",
        "BATCH_SIZE = 32\n",
        "LR = 5e-4                 # a bit higher for small model\n",
        "NUM_EPOCHS = 10\n",
        "PATIENCE = 3\n",
        "GRAD_CLIP = 1.0\n",
        "\n",
        "# checkpoint 路径\n",
        "CKPT_LAST = os.path.join(DATA_DIR, \"labtop_checkpoint_last.pt\")  # 断点续训用\n",
        "CKPT_BEST = os.path.join(DATA_DIR, \"labtop_best.pth\")      # 最优模型，用于 eval\n",
        "\n",
        "\n",
        "# ---------------- UTILS ----------------\n",
        "def set_seed(seed=42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "\n",
        "# ---------------- DATASET ----------------\n",
        "class LabTOPDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Uses only input_ids/type_ids from your preprocessed pkl.\n",
        "    Training now ignores type_ids for loss masking (LabTOP-style).\n",
        "    \"\"\"\n",
        "    def __init__(self, data_path):\n",
        "        with open(data_path, \"rb\") as f:\n",
        "            self.data = pickle.load(f)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = self.data[idx]\n",
        "        return {\n",
        "            \"input_ids\": torch.tensor(item[\"input_ids\"], dtype=torch.long),\n",
        "            \"type_ids\": torch.tensor(item[\"type_ids\"], dtype=torch.long),  # kept for potential analysis\n",
        "        }\n",
        "\n",
        "\n",
        "# ---------------- COLLATE FN ----------------\n",
        "def collate_fn(batch, pad_token_id):\n",
        "    \"\"\"\n",
        "    - Truncates to MAX_LEN (from the *right* by default)\n",
        "    - Pads to the longest length in batch\n",
        "    - Labels = input_ids shifted internally by GPT2; here we just\n",
        "      pass input_ids as labels with pad positions set to -100.\n",
        "    \"\"\"\n",
        "    input_ids = [b[\"input_ids\"] for b in batch]\n",
        "\n",
        "    # truncate sequences (keep last MAX_LEN tokens)\n",
        "    truncated = []\n",
        "    for seq in input_ids:\n",
        "        if len(seq) > MAX_LEN:\n",
        "            truncated.append(seq[-MAX_LEN:])\n",
        "        else:\n",
        "            truncated.append(seq)\n",
        "\n",
        "    input_ids_pad = torch.nn.utils.rnn.pad_sequence(\n",
        "        truncated, batch_first=True, padding_value=pad_token_id\n",
        "    )\n",
        "    attention_mask = (input_ids_pad != pad_token_id).long()\n",
        "\n",
        "    labels = input_ids_pad.clone()\n",
        "    labels[input_ids_pad == pad_token_id] = -100   # ignore pads only\n",
        "\n",
        "    return input_ids_pad, attention_mask, labels\n",
        "\n",
        "\n",
        "# ---------------- MODEL (small GPT2-style LM) ----------------\n",
        "class LabTOPGPT2Small(nn.Module):\n",
        "    \"\"\"\n",
        "    Small GPT-2 style LM:\n",
        "    - fewer layers / smaller hidden size for your budget\n",
        "    - still uses GPT2LMHeadModel for correct autoregressive behavior\n",
        "    \"\"\"\n",
        "    def __init__(self, tokenizer, d_model=256, n_heads=4, num_layers=4, max_len=MAX_LEN, dropout=0.1):\n",
        "        super().__init__()\n",
        "        vocab_size = len(tokenizer)\n",
        "        config = GPT2Config(\n",
        "            vocab_size=vocab_size,\n",
        "            n_embd=d_model,\n",
        "            n_head=n_heads,\n",
        "            n_layer=num_layers,\n",
        "            n_positions=max_len,\n",
        "            n_ctx=max_len,\n",
        "            resid_pdrop=dropout,\n",
        "            embd_pdrop=dropout,\n",
        "            attn_pdrop=dropout,\n",
        "            bos_token_id=tokenizer.bos_token_id,\n",
        "            eos_token_id=tokenizer.eos_token_id,\n",
        "        )\n",
        "        self.model = GPT2LMHeadModel(config)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask=None, labels=None):\n",
        "        \"\"\"\n",
        "        GPT2LMHeadModel will:\n",
        "        - apply causal masking internally\n",
        "        - compute next-token cross-entropy loss if labels is provided\n",
        "        \"\"\"\n",
        "        outputs = self.model(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            labels=labels,\n",
        "        )\n",
        "        return outputs  # has .logits and .loss\n",
        "\n",
        "    def generate_next_tokens(self, input_ids, attention_mask=None, max_new_tokens=6, bad_ids=None, eos_id=None):\n",
        "        \"\"\"\n",
        "        Simple greedy generation of a few tokens.\n",
        "        \"\"\"\n",
        "        self.eval()\n",
        "        device = input_ids.device\n",
        "        generated = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for _ in range(max_new_tokens):\n",
        "                if input_ids.size(1) > MAX_LEN:\n",
        "                    input_ids = input_ids[:, -MAX_LEN:]\n",
        "                    if attention_mask is not None:\n",
        "                        attention_mask = attention_mask[:, -MAX_LEN:]\n",
        "\n",
        "                outputs = self.model(input_ids, attention_mask=attention_mask)\n",
        "                logits = outputs.logits[:, -1, :]  # (B, vocab)\n",
        "                if bad_ids:\n",
        "                    logits[:, bad_ids] = -1e9\n",
        "\n",
        "                next_token = torch.argmax(logits, dim=-1)  # (B,)\n",
        "                next_id = next_token.item()\n",
        "                generated.append(next_id)\n",
        "\n",
        "                input_ids = torch.cat([input_ids, next_token.unsqueeze(0)], dim=1)\n",
        "                if attention_mask is not None:\n",
        "                    next_mask_token = torch.ones_like(next_token).unsqueeze(0)\n",
        "                    attention_mask = torch.cat([attention_mask, next_mask_token], dim=1)\n",
        "\n",
        "                if eos_id is not None and next_id == eos_id:\n",
        "                    break\n",
        "\n",
        "        return generated\n",
        "\n",
        "\n",
        "# ---------------- DECODE NUMERIC VALUE ----------------\n",
        "def decode_value(token_ids, tokenizer):\n",
        "    \"\"\"\n",
        "    Char-level decode: keep digits, '.', '-' and parse as float.\n",
        "    Returns None if parsing fails.\n",
        "    \"\"\"\n",
        "    text = tokenizer.decode(token_ids)\n",
        "    text = text.replace(\" \", \"\")\n",
        "    filtered = \"\".join(ch for ch in text if ch.isdigit() or ch in \".-\")\n",
        "    if filtered == \"\":\n",
        "        return None\n",
        "    try:\n",
        "        return float(filtered)\n",
        "    except Exception:\n",
        "        return None\n",
        "\n",
        "\n",
        "# ---------------- TRAIN ----------------\n",
        "def train_model(resume=False):\n",
        "    \"\"\"\n",
        "    完全断点续训版本：\n",
        "      - 如果 resume=True 且 CKPT_LAST 存在，则从上次保存的 epoch 继续\n",
        "      - 否则从头开始训练\n",
        "    \"\"\"\n",
        "    set_seed(42)\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f\"Using device: {device}\")\n",
        "\n",
        "    tokenizer = AutoTokenizer.from_pretrained(DATA_DIR)\n",
        "    if tokenizer.pad_token is None:\n",
        "        tokenizer.pad_token = tokenizer.eos_token\n",
        "    pad_id = tokenizer.pad_token_id\n",
        "\n",
        "    train_dataset = LabTOPDataset(os.path.join(DATA_DIR, \"train.pkl\"))\n",
        "    val_dataset   = LabTOPDataset(os.path.join(DATA_DIR, \"val.pkl\"))\n",
        "    print(\"Train dataset size:\", len(train_dataset))\n",
        "    print(\"Seq length example:\", len(train_dataset[0][\"input_ids\"]))\n",
        "\n",
        "    def collate_func(batch):\n",
        "        return collate_fn(batch, pad_token_id=pad_id)\n",
        "\n",
        "    train_loader = DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        shuffle=True,\n",
        "        collate_fn=collate_func,\n",
        "        num_workers=0,\n",
        "        pin_memory=(device.type == \"cuda\"),\n",
        "    )\n",
        "    val_loader = DataLoader(\n",
        "        val_dataset,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        shuffle=False,\n",
        "        collate_fn=collate_func,\n",
        "        num_workers=0,\n",
        "        pin_memory=(device.type == \"cuda\"),\n",
        "    )\n",
        "\n",
        "    model = LabTOPGPT2Small(tokenizer).to(device)\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=LR)\n",
        "    use_amp = (device.type == \"cuda\")\n",
        "    scaler = torch.cuda.amp.GradScaler(enabled=use_amp)\n",
        "\n",
        "    # ---- 断点恢复逻辑 ----\n",
        "    start_epoch = 0\n",
        "    best_val_loss = float(\"inf\")\n",
        "    patience_counter = 0\n",
        "\n",
        "    if resume and os.path.exists(CKPT_LAST):\n",
        "        print(f\"Resuming from checkpoint: {CKPT_LAST}\")\n",
        "        checkpoint = torch.load(CKPT_LAST, map_location=device)\n",
        "\n",
        "        model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
        "        optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
        "        scaler.load_state_dict(checkpoint[\"scaler_state_dict\"])\n",
        "\n",
        "        start_epoch      = checkpoint.get(\"epoch\", 0) + 1   # 下一个 epoch\n",
        "        best_val_loss    = checkpoint.get(\"best_val_loss\", float(\"inf\"))\n",
        "        patience_counter = checkpoint.get(\"patience_counter\", 0)\n",
        "\n",
        "        print(\n",
        "            f\"  -> start_epoch = {start_epoch}, \"\n",
        "            f\"best_val_loss = {best_val_loss:.4f}, \"\n",
        "            f\"patience_counter = {patience_counter}\"\n",
        "        )\n",
        "    else:\n",
        "        if resume:\n",
        "            print(f\"resume=True but checkpoint not found at {CKPT_LAST}, training from scratch.\")\n",
        "        else:\n",
        "            print(\"Training from scratch.\")\n",
        "\n",
        "    # ---- 训练循环 ----\n",
        "    for epoch in range(start_epoch, NUM_EPOCHS):\n",
        "        # ---------- TRAIN ----------\n",
        "        model.train()\n",
        "        total_loss = 0.0\n",
        "        count = 0\n",
        "\n",
        "        for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1} [train]\"):\n",
        "            input_ids, attention_mask, labels = [b.to(device) for b in batch]\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            with torch.cuda.amp.autocast(enabled=use_amp):\n",
        "                outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "                loss = outputs.loss\n",
        "\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.unscale_(optimizer)\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), GRAD_CLIP)\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            count += 1\n",
        "\n",
        "        avg_train_loss = total_loss / max(count, 1)\n",
        "        print(f\"Epoch {epoch+1} Train Loss: {avg_train_loss:.4f}\")\n",
        "\n",
        "        # ---------- VALIDATION ----------\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        val_count = 0\n",
        "        with torch.no_grad():\n",
        "            for batch in tqdm(val_loader, desc=f\"Epoch {epoch+1} [val]\"):\n",
        "                input_ids, attention_mask, labels = [b.to(device) for b in batch]\n",
        "                with torch.cuda.amp.autocast(enabled=use_amp):\n",
        "                    outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "                    loss = outputs.loss\n",
        "                val_loss += loss.item()\n",
        "                val_count += 1\n",
        "\n",
        "        avg_val_loss = val_loss / max(val_count, 1)\n",
        "        print(f\"Epoch {epoch+1} Val Loss: {avg_val_loss:.4f}\")\n",
        "\n",
        "        # ---------- 保存最优模型（仅参数，用于 eval） ----------\n",
        "        if avg_val_loss < best_val_loss:\n",
        "            best_val_loss = avg_val_loss\n",
        "            patience_counter = 0\n",
        "            torch.save(model.state_dict(), CKPT_BEST)\n",
        "            print(f\"Saved BEST model (val loss={best_val_loss:.4f}) to {CKPT_BEST}\")\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "            print(f\"No improvement. Patience: {patience_counter}/{PATIENCE}\")\n",
        "\n",
        "        # ---------- 保存完整断点（每个 epoch 都保存） ----------\n",
        "        last_state = {\n",
        "            \"epoch\": epoch,\n",
        "            \"model_state_dict\": model.state_dict(),\n",
        "            \"optimizer_state_dict\": optimizer.state_dict(),\n",
        "            \"scaler_state_dict\": scaler.state_dict(),\n",
        "            \"best_val_loss\": best_val_loss,\n",
        "            \"patience_counter\": patience_counter,\n",
        "        }\n",
        "        torch.save(last_state, CKPT_LAST)\n",
        "        print(f\"Saved training checkpoint to {CKPT_LAST}\")\n",
        "\n",
        "        # ---------- EARLY STOP ----------\n",
        "        if patience_counter >= PATIENCE:\n",
        "            print(\"Early stopping triggered.\")\n",
        "            break\n",
        "\n",
        "    print(\"Training complete.\")\n",
        "\n",
        "\n",
        "# ---------------- EVALUATION ----------------\n",
        "def evaluate_model(resume=False, save_every=10000):\n",
        "    test_eval_path = os.path.join(DATA_DIR, \"test_eval.pkl\")\n",
        "\n",
        "    if not os.path.exists(test_eval_path):\n",
        "        print(\"test_eval.pkl not found; nothing to evaluate.\")\n",
        "        return\n",
        "    if not os.path.exists(CKPT_BEST):\n",
        "        print(f\"Best model checkpoint {CKPT_BEST} not found; train first.\")\n",
        "        return\n",
        "\n",
        "    # 进度文件，用来断点续 eval\n",
        "    PROGRESS_PATH = os.path.join(DATA_DIR, \"eval_progress.pkl\")\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        device = torch.device(\"cuda\")\n",
        "    elif torch.backends.mps.is_available():\n",
        "        device = torch.device(\"mps\")\n",
        "    else:\n",
        "        device = torch.device(\"cpu\")\n",
        "    print(f\"Using device: {device}\")\n",
        "\n",
        "    tokenizer = AutoTokenizer.from_pretrained(DATA_DIR)\n",
        "    if tokenizer.pad_token is None:\n",
        "        tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "    with open(test_eval_path, \"rb\") as f:\n",
        "        test_data = pickle.load(f)\n",
        "    print(f\"Total examples in test_eval: {len(test_data)}\")\n",
        "\n",
        "    model = LabTOPGPT2Small(tokenizer).to(device)\n",
        "    model.load_state_dict(torch.load(CKPT_BEST, map_location=device))\n",
        "    model.eval()\n",
        "\n",
        "    use_amp = (device.type == \"cuda\")\n",
        "\n",
        "    # tokens we never want as value predictions\n",
        "    bad_tokens = [\n",
        "        \"labevent\", \"inputevent\", \"outputevent\",\n",
        "        \"gender\", \"age\", \"race\",\n",
        "        \"procedureevent\", \"emarevent\", \"microevent\"\n",
        "    ]\n",
        "    vocab = tokenizer.get_vocab()\n",
        "    bad_ids = [tokenizer.convert_tokens_to_ids(t) for t in bad_tokens if t in vocab]\n",
        "\n",
        "    eoe_id = tokenizer.convert_tokens_to_ids(\"[EOE]\")\n",
        "    max_new_tokens = 6\n",
        "\n",
        "    # --------- 恢复 / 初始化进度 ---------\n",
        "    if resume and os.path.exists(PROGRESS_PATH):\n",
        "        print(f\"Resuming evaluation from {PROGRESS_PATH}\")\n",
        "        prog = pickle.load(open(PROGRESS_PATH, \"rb\"))\n",
        "        predictions     = prog[\"predictions\"]\n",
        "        ground_truths   = prog[\"ground_truths\"]\n",
        "        itemids         = prog[\"itemids\"]\n",
        "        event_types     = prog[\"event_types\"]\n",
        "        example_indices = prog[\"example_indices\"]\n",
        "        start_idx       = prog[\"next_idx\"]\n",
        "    else:\n",
        "        predictions     = []\n",
        "        ground_truths   = []\n",
        "        itemids         = []\n",
        "        event_types     = []\n",
        "        example_indices = []\n",
        "        start_idx       = 0\n",
        "\n",
        "    print(f\"Start evaluating from index {start_idx} ...\")\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    for idx in tqdm(range(start_idx, len(test_data)), desc=\"Evaluating\"):\n",
        "        item = test_data[idx]\n",
        "        prompt_ids = item[\"prompt_ids\"]\n",
        "        true_val   = item[\"valuenum\"]\n",
        "        itemid     = item.get(\"itemid\", None)\n",
        "        e_type     = item.get(\"event_type\", \"unknown\")\n",
        "\n",
        "        # truncate prompt from the left to MAX_LEN\n",
        "        if len(prompt_ids) > MAX_LEN:\n",
        "            prompt_ids = prompt_ids[-MAX_LEN:]\n",
        "\n",
        "        input_tensor = torch.tensor([prompt_ids], dtype=torch.long).to(device)\n",
        "        attn_mask    = torch.ones_like(input_tensor, dtype=torch.long).to(device)\n",
        "\n",
        "        # 只前几个样本打印 debug\n",
        "        if idx < start_idx + 3:\n",
        "            decoded_prompt_tail = tokenizer.decode(prompt_ids[-80:])\n",
        "            print(f\"\\n=== Debug sample {idx} ===\")\n",
        "            print(f\"Prompt tail: {decoded_prompt_tail}\")\n",
        "            print(f\"True value: {true_val}, itemid: {itemid}, event_type: {e_type}\")\n",
        "\n",
        "        with torch.no_grad():\n",
        "            with torch.cuda.amp.autocast(enabled=use_amp):\n",
        "                generated_ids = model.generate_next_tokens(\n",
        "                    input_ids=input_tensor,\n",
        "                    attention_mask=attn_mask,\n",
        "                    max_new_tokens=max_new_tokens,\n",
        "                    bad_ids=bad_ids,\n",
        "                    eos_id=eoe_id,\n",
        "                )\n",
        "\n",
        "        pred_val = decode_value(generated_ids, tokenizer)\n",
        "        if pred_val is None or not isfinite(pred_val) or abs(pred_val) > 1e4:\n",
        "            # 无效预测，跳过但仍然推进 idx\n",
        "            continue\n",
        "\n",
        "        if idx < start_idx + 3:\n",
        "            decoded_generated = tokenizer.decode(generated_ids)\n",
        "            print(f\"Generated tokens: {decoded_generated}\")\n",
        "            print(f\"Decoded pred_val: {pred_val}\")\n",
        "\n",
        "        predictions.append(pred_val)\n",
        "        ground_truths.append(true_val)\n",
        "        itemids.append(itemid)\n",
        "        event_types.append(e_type)\n",
        "        example_indices.append(idx)\n",
        "\n",
        "        # --------- 定期保存 eval 进度 ---------\n",
        "        if (idx + 1) % save_every == 0:\n",
        "            prog = {\n",
        "                \"predictions\": predictions,\n",
        "                \"ground_truths\": ground_truths,\n",
        "                \"itemids\": itemids,\n",
        "                \"event_types\": event_types,\n",
        "                \"example_indices\": example_indices,\n",
        "                \"next_idx\": idx + 1,  # 下次从这里继续\n",
        "            }\n",
        "            with open(PROGRESS_PATH, \"wb\") as f:\n",
        "                pickle.dump(prog, f)\n",
        "            print(f\"\\n[Checkpoint] Saved eval progress at idx={idx+1} -> {PROGRESS_PATH}\")\n",
        "\n",
        "    # 全部跑完，删除进度文件\n",
        "    if os.path.exists(PROGRESS_PATH):\n",
        "        os.remove(PROGRESS_PATH)\n",
        "        print(f\"Removed eval progress file {PROGRESS_PATH}\")\n",
        "\n",
        "    if len(predictions) == 0:\n",
        "        print(\"No valid predictions generated.\")\n",
        "        return\n",
        "\n",
        "    preds  = np.array(predictions)\n",
        "    truths = np.array(ground_truths)\n",
        "\n",
        "    mae  = np.mean(np.abs(preds - truths))\n",
        "    rmse = np.sqrt(np.mean((preds - truths) ** 2))\n",
        "\n",
        "    p1   = np.percentile(truths, 1)\n",
        "    p99  = np.percentile(truths, 99)\n",
        "    range_val = p99 - p1 if p99 > p1 else 1e-6\n",
        "    nmae = mae / range_val\n",
        "\n",
        "    denom = (np.abs(truths) + np.abs(preds))\n",
        "    mask = denom > 0\n",
        "    if np.sum(mask) > 0:\n",
        "        smape = np.mean(2 * np.abs(preds[mask] - truths[mask]) / denom[mask])\n",
        "    else:\n",
        "        smape = 0.0\n",
        "\n",
        "    elapsed = time.time() - start_time\n",
        "    print(f\"\\nEvaluated {len(preds)} samples in {elapsed:.2f} seconds.\")\n",
        "    print(f\"Test MAE:   {mae:.4f}\")\n",
        "    print(f\"Test RMSE:  {rmse:.4f}\")\n",
        "    print(f\"Test NMAE:  {nmae:.4f}\")\n",
        "    print(f\"Test SMAPE: {smape:.4f}\")\n",
        "\n",
        "    # 保存 sample predictions\n",
        "    csv_path = os.path.join(DATA_DIR, \"test_predictions.csv\")\n",
        "    print(f\"Saving predictions to: {csv_path}\")\n",
        "    import csv\n",
        "    with open(csv_path, \"w\", newline=\"\") as f:\n",
        "        writer = csv.writer(f)\n",
        "        writer.writerow([\"index\", \"itemid\", \"event_type\", \"true_value\", \"pred_value\"])\n",
        "        for i, iid, et, truth, pred in zip(example_indices, itemids, event_types, truths, preds):\n",
        "            writer.writerow([i, iid, et, truth, pred])\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # 训练\n",
        "    RESUME_TRAIN = False\n",
        "    train_model(resume=RESUME_TRAIN)\n",
        "\n",
        "    # eval：第一次跑用 resume=False，之后断了想接着跑就改成 True\n",
        "    # RESUME_EVAL = False\n",
        "    # evaluate_model(resume=RESUME_EVAL)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 550
        },
        "id": "xIvHvyyZVGtW",
        "outputId": "595d2d8c-ca6f-44ee-bc9d-cc00d93aa897"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Train dataset size: 367830\n",
            "Seq length example: 276\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2947388651.py:222: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler(enabled=use_amp)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training from scratch.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1 [train]:   0%|          | 0/11495 [00:00<?, ?it/s]/tmp/ipython-input-2947388651.py:263: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=use_amp):\n",
            "`loss_type=None` was set in the config but it is unrecognized. Using the default loss: `ForCausalLMLoss`.\n",
            "Epoch 1 [train]:  37%|███▋      | 4278/11495 [08:06<13:40,  8.79it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2947388651.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    502\u001b[0m     \u001b[0;31m# 训练\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m     \u001b[0mRESUME_TRAIN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m     \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresume\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mRESUME_TRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    505\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m     \u001b[0;31m# eval：第一次跑用 resume=False，之后断了想接着跑就改成 True\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2947388651.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(resume)\u001b[0m\n\u001b[1;32m    268\u001b[0m             \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munscale_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGRAD_CLIP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m             \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m             \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/amp/grad_scaler.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, optimizer, *args, **kwargs)\u001b[0m\n\u001b[1;32m    460\u001b[0m         )\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m         \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_opt_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m         \u001b[0moptimizer_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"stage\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOptState\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSTEPPED\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/amp/grad_scaler.py\u001b[0m in \u001b[0;36m_maybe_opt_step\u001b[0;34m(self, optimizer, optimizer_state, *args, **kwargs)\u001b[0m\n\u001b[1;32m    354\u001b[0m     ) -> Optional[float]:\n\u001b[1;32m    355\u001b[0m         \u001b[0mretval\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"found_inf_per_device\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m             \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mretval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/amp/grad_scaler.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    354\u001b[0m     ) -> Optional[float]:\n\u001b[1;32m    355\u001b[0m         \u001b[0mretval\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"found_inf_per_device\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m             \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mretval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-lII-pOA672f",
        "outputId": "745caf77-474a-46c2-a94c-fe0ad5dea4d6"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n",
            "Total examples in test_eval: 1229791\n",
            "Start evaluating from index 0 ...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating:   0%|          | 0/1229791 [00:00<?, ?it/s]/tmp/ipython-input-1062691222.py:417: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=use_amp):\n",
            "Evaluating:   0%|          | 4/1229791 [00:00<10:05:38, 33.84it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Debug sample 0 ===\n",
            "Prompt tail: gender f age 53 race other [DAY0] [SUN] [00h] [20m] labevent base excess\n",
            "True value: 0.0, itemid: 50802, event_type: labevent\n",
            "Generated tokens: - 1 meq / l\n",
            "Decoded pred_val: -1.0\n",
            "\n",
            "=== Debug sample 1 ===\n",
            "Prompt tail: gender f age 53 race other [DAY0] [SUN] [00h] [20m] labevent base excess 0 meq / l [EOE] [DAY0] [SUN] [00h] [20m] labevent sodium, whole blood\n",
            "True value: 137.0, itemid: 50824, event_type: labevent\n",
            "Generated tokens: 1 3 7 meq /\n",
            "Decoded pred_val: 137.0\n",
            "\n",
            "=== Debug sample 2 ===\n",
            "Prompt tail: gender f age 53 race other [DAY0] [SUN] [00h] [20m] labevent base excess 0 meq / l [EOE] [DAY0] [SUN] [00h] [20m] labevent sodium, whole blood 1 3 7 meq / l [EOE] [DAY0] [SUN] [00h] [20m] labevent potassium, whole blood\n",
            "True value: 3.4, itemid: 50822, event_type: labevent\n",
            "Generated tokens: 4. 1 meq /\n",
            "Decoded pred_val: 4.1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating:   1%|          | 10003/1229791 [04:45<10:08:08, 33.43it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Checkpoint] Saved eval progress at idx=10000 -> /content/drive/MyDrive/labtop2/v1/eval_progress.pkl\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating:   2%|▏         | 20004/1229791 [09:31<9:40:11, 34.75it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Checkpoint] Saved eval progress at idx=20000 -> /content/drive/MyDrive/labtop2/v1/eval_progress.pkl\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating:   2%|▏         | 30004/1229791 [14:16<10:41:15, 31.18it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Checkpoint] Saved eval progress at idx=30000 -> /content/drive/MyDrive/labtop2/v1/eval_progress.pkl\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating:   3%|▎         | 40005/1229791 [19:05<9:50:30, 33.58it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Checkpoint] Saved eval progress at idx=40000 -> /content/drive/MyDrive/labtop2/v1/eval_progress.pkl\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating:   4%|▍         | 50005/1229791 [23:48<10:03:43, 32.57it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Checkpoint] Saved eval progress at idx=50000 -> /content/drive/MyDrive/labtop2/v1/eval_progress.pkl\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating:   5%|▍         | 60004/1229791 [28:32<10:11:08, 31.90it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Checkpoint] Saved eval progress at idx=60000 -> /content/drive/MyDrive/labtop2/v1/eval_progress.pkl\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating:   6%|▌         | 70005/1229791 [33:17<9:55:27, 32.46it/s] "
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Checkpoint] Saved eval progress at idx=70000 -> /content/drive/MyDrive/labtop2/v1/eval_progress.pkl\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating:   7%|▋         | 80007/1229791 [38:01<9:44:36, 32.78it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Checkpoint] Saved eval progress at idx=80000 -> /content/drive/MyDrive/labtop2/v1/eval_progress.pkl\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating:   7%|▋         | 90005/1229791 [42:45<10:00:51, 31.62it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Checkpoint] Saved eval progress at idx=90000 -> /content/drive/MyDrive/labtop2/v1/eval_progress.pkl\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating:   8%|▊         | 100006/1229791 [47:29<9:40:53, 32.42it/s] "
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Checkpoint] Saved eval progress at idx=100000 -> /content/drive/MyDrive/labtop2/v1/eval_progress.pkl\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating:   9%|▉         | 110007/1229791 [52:09<9:28:55, 32.80it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Checkpoint] Saved eval progress at idx=110000 -> /content/drive/MyDrive/labtop2/v1/eval_progress.pkl\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating:  10%|▉         | 120006/1229791 [56:53<9:37:25, 32.03it/s] "
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Checkpoint] Saved eval progress at idx=120000 -> /content/drive/MyDrive/labtop2/v1/eval_progress.pkl\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating:  11%|█         | 130003/1229791 [1:01:39<9:26:08, 32.38it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Checkpoint] Saved eval progress at idx=130000 -> /content/drive/MyDrive/labtop2/v1/eval_progress.pkl\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating:  11%|█▏        | 140005/1229791 [1:06:26<10:11:42, 29.69it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Checkpoint] Saved eval progress at idx=140000 -> /content/drive/MyDrive/labtop2/v1/eval_progress.pkl\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating:  12%|█▏        | 150005/1229791 [1:11:09<9:45:19, 30.75it/s] "
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Checkpoint] Saved eval progress at idx=150000 -> /content/drive/MyDrive/labtop2/v1/eval_progress.pkl\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating:  13%|█▎        | 160004/1229791 [1:15:52<9:08:04, 32.53it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Checkpoint] Saved eval progress at idx=160000 -> /content/drive/MyDrive/labtop2/v1/eval_progress.pkl\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating:  14%|█▍        | 170006/1229791 [1:20:35<9:07:51, 32.24it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Checkpoint] Saved eval progress at idx=170000 -> /content/drive/MyDrive/labtop2/v1/eval_progress.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating:  15%|█▍        | 180007/1229791 [1:25:21<9:30:10, 30.69it/s] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Checkpoint] Saved eval progress at idx=180000 -> /content/drive/MyDrive/labtop2/v1/eval_progress.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating:  15%|█▌        | 190006/1229791 [1:30:07<9:03:41, 31.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Checkpoint] Saved eval progress at idx=190000 -> /content/drive/MyDrive/labtop2/v1/eval_progress.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating:  16%|█▋        | 200006/1229791 [1:34:53<9:20:30, 30.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Checkpoint] Saved eval progress at idx=200000 -> /content/drive/MyDrive/labtop2/v1/eval_progress.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating:  17%|█▋        | 210005/1229791 [1:39:36<9:20:51, 30.30it/s] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Checkpoint] Saved eval progress at idx=210000 -> /content/drive/MyDrive/labtop2/v1/eval_progress.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating:  18%|█▊        | 220004/1229791 [1:44:20<9:22:33, 29.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Checkpoint] Saved eval progress at idx=220000 -> /content/drive/MyDrive/labtop2/v1/eval_progress.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating:  19%|█▊        | 230004/1229791 [1:49:05<9:35:51, 28.94it/s] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Checkpoint] Saved eval progress at idx=230000 -> /content/drive/MyDrive/labtop2/v1/eval_progress.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating:  20%|█▉        | 240003/1229791 [1:53:52<9:48:52, 28.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Checkpoint] Saved eval progress at idx=240000 -> /content/drive/MyDrive/labtop2/v1/eval_progress.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating:  20%|██        | 250004/1229791 [1:58:35<9:05:30, 29.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Checkpoint] Saved eval progress at idx=250000 -> /content/drive/MyDrive/labtop2/v1/eval_progress.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating:  21%|██        | 260006/1229791 [2:03:19<9:11:58, 29.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Checkpoint] Saved eval progress at idx=260000 -> /content/drive/MyDrive/labtop2/v1/eval_progress.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating:  22%|██▏       | 270007/1229791 [2:08:06<9:02:12, 29.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Checkpoint] Saved eval progress at idx=270000 -> /content/drive/MyDrive/labtop2/v1/eval_progress.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating:  23%|██▎       | 280003/1229791 [2:12:50<10:22:29, 25.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Checkpoint] Saved eval progress at idx=280000 -> /content/drive/MyDrive/labtop2/v1/eval_progress.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating:  24%|██▎       | 290003/1229791 [2:17:35<9:48:09, 26.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Checkpoint] Saved eval progress at idx=290000 -> /content/drive/MyDrive/labtop2/v1/eval_progress.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating:  24%|██▍       | 300004/1229791 [2:22:19<8:23:02, 30.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Checkpoint] Saved eval progress at idx=300000 -> /content/drive/MyDrive/labtop2/v1/eval_progress.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating:  25%|██▌       | 310004/1229791 [2:27:02<8:05:45, 31.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Checkpoint] Saved eval progress at idx=310000 -> /content/drive/MyDrive/labtop2/v1/eval_progress.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating:  26%|██▌       | 320004/1229791 [2:31:44<9:13:15, 27.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Checkpoint] Saved eval progress at idx=320000 -> /content/drive/MyDrive/labtop2/v1/eval_progress.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating:  27%|██▋       | 330008/1229791 [2:36:31<8:06:55, 30.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Checkpoint] Saved eval progress at idx=330000 -> /content/drive/MyDrive/labtop2/v1/eval_progress.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating:  28%|██▊       | 340006/1229791 [2:41:12<8:18:00, 29.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Checkpoint] Saved eval progress at idx=340000 -> /content/drive/MyDrive/labtop2/v1/eval_progress.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating:  28%|██▊       | 350005/1229791 [2:45:57<8:27:55, 28.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Checkpoint] Saved eval progress at idx=350000 -> /content/drive/MyDrive/labtop2/v1/eval_progress.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating:  29%|██▉       | 360005/1229791 [2:50:43<8:54:58, 27.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Checkpoint] Saved eval progress at idx=360000 -> /content/drive/MyDrive/labtop2/v1/eval_progress.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating:  30%|███       | 370005/1229791 [2:55:28<8:25:24, 28.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Checkpoint] Saved eval progress at idx=370000 -> /content/drive/MyDrive/labtop2/v1/eval_progress.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating:  31%|███       | 380005/1229791 [3:00:15<8:39:28, 27.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Checkpoint] Saved eval progress at idx=380000 -> /content/drive/MyDrive/labtop2/v1/eval_progress.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating:  32%|███▏      | 390003/1229791 [3:05:01<9:35:29, 24.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Checkpoint] Saved eval progress at idx=390000 -> /content/drive/MyDrive/labtop2/v1/eval_progress.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating:  33%|███▎      | 400005/1229791 [3:09:45<8:26:28, 27.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Checkpoint] Saved eval progress at idx=400000 -> /content/drive/MyDrive/labtop2/v1/eval_progress.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating:  33%|███▎      | 410006/1229791 [3:14:24<8:06:10, 28.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Checkpoint] Saved eval progress at idx=410000 -> /content/drive/MyDrive/labtop2/v1/eval_progress.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating:  34%|███▍      | 420006/1229791 [3:19:06<8:28:29, 26.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Checkpoint] Saved eval progress at idx=420000 -> /content/drive/MyDrive/labtop2/v1/eval_progress.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating:  35%|███▍      | 430004/1229791 [3:23:46<7:36:24, 29.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Checkpoint] Saved eval progress at idx=430000 -> /content/drive/MyDrive/labtop2/v1/eval_progress.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating:  36%|███▌      | 440005/1229791 [3:28:24<8:13:46, 26.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Checkpoint] Saved eval progress at idx=440000 -> /content/drive/MyDrive/labtop2/v1/eval_progress.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating:  37%|███▋      | 450003/1229791 [3:33:01<8:43:33, 24.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Checkpoint] Saved eval progress at idx=450000 -> /content/drive/MyDrive/labtop2/v1/eval_progress.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating:  37%|███▋      | 460005/1229791 [3:37:41<7:50:25, 27.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Checkpoint] Saved eval progress at idx=460000 -> /content/drive/MyDrive/labtop2/v1/eval_progress.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating:  38%|███▊      | 470006/1229791 [3:42:27<7:32:02, 28.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Checkpoint] Saved eval progress at idx=470000 -> /content/drive/MyDrive/labtop2/v1/eval_progress.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating:  39%|███▉      | 480007/1229791 [3:47:14<7:38:50, 27.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Checkpoint] Saved eval progress at idx=480000 -> /content/drive/MyDrive/labtop2/v1/eval_progress.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating:  40%|███▉      | 490004/1229791 [3:52:00<8:21:49, 24.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Checkpoint] Saved eval progress at idx=490000 -> /content/drive/MyDrive/labtop2/v1/eval_progress.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating:  41%|████      | 500004/1229791 [3:56:49<7:54:39, 25.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Checkpoint] Saved eval progress at idx=500000 -> /content/drive/MyDrive/labtop2/v1/eval_progress.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating:  41%|████▏     | 510004/1229791 [4:01:38<7:52:46, 25.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Checkpoint] Saved eval progress at idx=510000 -> /content/drive/MyDrive/labtop2/v1/eval_progress.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating:  42%|████▏     | 520007/1229791 [4:06:23<7:17:43, 27.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Checkpoint] Saved eval progress at idx=520000 -> /content/drive/MyDrive/labtop2/v1/eval_progress.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating:  43%|████▎     | 530005/1229791 [4:11:13<7:10:22, 27.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Checkpoint] Saved eval progress at idx=530000 -> /content/drive/MyDrive/labtop2/v1/eval_progress.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating:  44%|████▍     | 540005/1229791 [4:16:01<7:36:26, 25.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Checkpoint] Saved eval progress at idx=540000 -> /content/drive/MyDrive/labtop2/v1/eval_progress.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating:  45%|████▍     | 550004/1229791 [4:20:46<7:40:57, 24.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Checkpoint] Saved eval progress at idx=550000 -> /content/drive/MyDrive/labtop2/v1/eval_progress.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating:  46%|████▌     | 560003/1229791 [4:25:33<8:22:51, 22.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Checkpoint] Saved eval progress at idx=560000 -> /content/drive/MyDrive/labtop2/v1/eval_progress.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating:  46%|████▋     | 570003/1229791 [4:30:24<8:07:03, 22.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Checkpoint] Saved eval progress at idx=570000 -> /content/drive/MyDrive/labtop2/v1/eval_progress.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating:  47%|████▋     | 580006/1229791 [4:35:11<7:06:16, 25.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Checkpoint] Saved eval progress at idx=580000 -> /content/drive/MyDrive/labtop2/v1/eval_progress.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating:  48%|████▊     | 590003/1229791 [4:40:00<8:24:00, 21.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Checkpoint] Saved eval progress at idx=590000 -> /content/drive/MyDrive/labtop2/v1/eval_progress.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating:  49%|████▉     | 600005/1229791 [4:44:47<7:10:37, 24.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Checkpoint] Saved eval progress at idx=600000 -> /content/drive/MyDrive/labtop2/v1/eval_progress.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating:  50%|████▉     | 610007/1229791 [4:49:35<6:48:26, 25.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Checkpoint] Saved eval progress at idx=610000 -> /content/drive/MyDrive/labtop2/v1/eval_progress.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating:  50%|█████     | 620003/1229791 [4:54:25<8:02:52, 21.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Checkpoint] Saved eval progress at idx=620000 -> /content/drive/MyDrive/labtop2/v1/eval_progress.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating:  51%|█████     | 630004/1229791 [4:59:14<6:45:36, 24.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Checkpoint] Saved eval progress at idx=630000 -> /content/drive/MyDrive/labtop2/v1/eval_progress.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating:  52%|█████▏    | 640004/1229791 [5:04:04<6:31:51, 25.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Checkpoint] Saved eval progress at idx=640000 -> /content/drive/MyDrive/labtop2/v1/eval_progress.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating:  53%|█████▎    | 650004/1229791 [5:08:52<6:46:44, 23.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Checkpoint] Saved eval progress at idx=650000 -> /content/drive/MyDrive/labtop2/v1/eval_progress.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating:  54%|█████▎    | 660003/1229791 [5:13:42<7:27:38, 21.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Checkpoint] Saved eval progress at idx=660000 -> /content/drive/MyDrive/labtop2/v1/eval_progress.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating:  54%|█████▍    | 670003/1229791 [5:18:30<7:36:26, 20.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Checkpoint] Saved eval progress at idx=670000 -> /content/drive/MyDrive/labtop2/v1/eval_progress.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating:  55%|█████▌    | 680006/1229791 [5:23:19<6:27:44, 23.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Checkpoint] Saved eval progress at idx=680000 -> /content/drive/MyDrive/labtop2/v1/eval_progress.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating:  56%|█████▌    | 690004/1229791 [5:28:05<6:09:55, 24.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Checkpoint] Saved eval progress at idx=690000 -> /content/drive/MyDrive/labtop2/v1/eval_progress.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating:  57%|█████▋    | 700003/1229791 [5:32:50<7:20:45, 20.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Checkpoint] Saved eval progress at idx=700000 -> /content/drive/MyDrive/labtop2/v1/eval_progress.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating:  58%|█████▊    | 710006/1229791 [5:37:37<5:54:02, 24.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Checkpoint] Saved eval progress at idx=710000 -> /content/drive/MyDrive/labtop2/v1/eval_progress.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating:  59%|█████▊    | 720004/1229791 [5:42:17<5:58:34, 23.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Checkpoint] Saved eval progress at idx=720000 -> /content/drive/MyDrive/labtop2/v1/eval_progress.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating:  59%|█████▉    | 730004/1229791 [5:46:57<5:59:32, 23.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Checkpoint] Saved eval progress at idx=730000 -> /content/drive/MyDrive/labtop2/v1/eval_progress.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating:  60%|██████    | 740004/1229791 [5:51:38<5:38:41, 24.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Checkpoint] Saved eval progress at idx=740000 -> /content/drive/MyDrive/labtop2/v1/eval_progress.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating:  61%|██████    | 750007/1229791 [5:56:19<5:29:44, 24.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Checkpoint] Saved eval progress at idx=750000 -> /content/drive/MyDrive/labtop2/v1/eval_progress.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating:  62%|██████▏   | 760005/1229791 [6:00:58<5:32:27, 23.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Checkpoint] Saved eval progress at idx=760000 -> /content/drive/MyDrive/labtop2/v1/eval_progress.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating:  63%|██████▎   | 770003/1229791 [6:05:38<6:25:08, 19.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Checkpoint] Saved eval progress at idx=770000 -> /content/drive/MyDrive/labtop2/v1/eval_progress.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating:  63%|██████▎   | 780004/1229791 [6:10:26<5:27:29, 22.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Checkpoint] Saved eval progress at idx=780000 -> /content/drive/MyDrive/labtop2/v1/eval_progress.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating:  64%|██████▍   | 790004/1229791 [6:15:17<5:36:43, 21.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Checkpoint] Saved eval progress at idx=790000 -> /content/drive/MyDrive/labtop2/v1/eval_progress.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating:  65%|██████▌   | 800006/1229791 [6:20:04<5:08:06, 23.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Checkpoint] Saved eval progress at idx=800000 -> /content/drive/MyDrive/labtop2/v1/eval_progress.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating:  66%|██████▌   | 810006/1229791 [6:24:50<4:59:11, 23.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Checkpoint] Saved eval progress at idx=810000 -> /content/drive/MyDrive/labtop2/v1/eval_progress.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating:  67%|██████▋   | 820005/1229791 [6:29:36<4:51:41, 23.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Checkpoint] Saved eval progress at idx=820000 -> /content/drive/MyDrive/labtop2/v1/eval_progress.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating:  67%|██████▋   | 830003/1229791 [6:34:24<5:44:37, 19.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Checkpoint] Saved eval progress at idx=830000 -> /content/drive/MyDrive/labtop2/v1/eval_progress.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating:  68%|██████▊   | 840003/1229791 [6:39:11<5:23:49, 20.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Checkpoint] Saved eval progress at idx=840000 -> /content/drive/MyDrive/labtop2/v1/eval_progress.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating:  69%|██████▉   | 850003/1229791 [6:44:00<5:07:50, 20.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Checkpoint] Saved eval progress at idx=850000 -> /content/drive/MyDrive/labtop2/v1/eval_progress.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating:  70%|██████▉   | 860004/1229791 [6:48:47<4:47:50, 21.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Checkpoint] Saved eval progress at idx=860000 -> /content/drive/MyDrive/labtop2/v1/eval_progress.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating:  71%|███████   | 870005/1229791 [6:53:36<4:13:59, 23.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Checkpoint] Saved eval progress at idx=870000 -> /content/drive/MyDrive/labtop2/v1/eval_progress.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating:  72%|███████▏  | 880007/1229791 [6:58:23<4:25:08, 21.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Checkpoint] Saved eval progress at idx=880000 -> /content/drive/MyDrive/labtop2/v1/eval_progress.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating:  72%|███████▏  | 890006/1229791 [7:03:13<4:24:48, 21.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Checkpoint] Saved eval progress at idx=890000 -> /content/drive/MyDrive/labtop2/v1/eval_progress.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating:  73%|███████▎  | 900003/1229791 [7:08:03<4:41:45, 19.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Checkpoint] Saved eval progress at idx=900000 -> /content/drive/MyDrive/labtop2/v1/eval_progress.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating:  74%|███████▍  | 910004/1229791 [7:12:53<4:08:38, 21.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Checkpoint] Saved eval progress at idx=910000 -> /content/drive/MyDrive/labtop2/v1/eval_progress.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating:  75%|███████▍  | 920005/1229791 [7:17:40<4:02:25, 21.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Checkpoint] Saved eval progress at idx=920000 -> /content/drive/MyDrive/labtop2/v1/eval_progress.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating:  76%|███████▌  | 930006/1229791 [7:22:29<3:52:19, 21.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Checkpoint] Saved eval progress at idx=930000 -> /content/drive/MyDrive/labtop2/v1/eval_progress.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating:  76%|███████▋  | 940003/1229791 [7:27:18<4:10:25, 19.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Checkpoint] Saved eval progress at idx=940000 -> /content/drive/MyDrive/labtop2/v1/eval_progress.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating:  77%|███████▋  | 950007/1229791 [7:32:07<3:40:20, 21.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Checkpoint] Saved eval progress at idx=950000 -> /content/drive/MyDrive/labtop2/v1/eval_progress.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating:  78%|███████▊  | 960005/1229791 [7:36:56<3:37:01, 20.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Checkpoint] Saved eval progress at idx=960000 -> /content/drive/MyDrive/labtop2/v1/eval_progress.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating:  79%|███████▉  | 970003/1229791 [7:41:46<4:02:18, 17.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Checkpoint] Saved eval progress at idx=970000 -> /content/drive/MyDrive/labtop2/v1/eval_progress.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating:  79%|███████▉  | 975457/1229791 [7:44:24<2:04:17, 34.10it/s]"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import time\n",
        "import pickle\n",
        "import random\n",
        "import numpy as np\n",
        "from math import isfinite\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from tqdm import tqdm\n",
        "from transformers import AutoTokenizer, GPT2Config, GPT2LMHeadModel\n",
        "\n",
        "# ---------------- CONFIG ----------------\n",
        "DATA_DIR = \"/content/drive/MyDrive/labtop2/v1\"  # <-- adjust\n",
        "MAX_LEN = 1024            # must be <= preprocessor max_len\n",
        "BATCH_SIZE = 32\n",
        "LR = 5e-4                 # a bit higher for small model\n",
        "NUM_EPOCHS = 10\n",
        "PATIENCE = 3\n",
        "GRAD_CLIP = 1.0\n",
        "\n",
        "# checkpoint 路径\n",
        "CKPT_LAST = os.path.join(DATA_DIR, \"labtop_checkpoint_last.pt\")  # 断点续训用\n",
        "CKPT_BEST = os.path.join(DATA_DIR, \"labtop_v1.pth\")      # 最优模型，用于 eval\n",
        "\n",
        "\n",
        "# ---------------- UTILS ----------------\n",
        "def set_seed(seed=42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "\n",
        "# ---------------- DATASET ----------------\n",
        "class LabTOPDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Uses only input_ids/type_ids from your preprocessed pkl.\n",
        "    Training now ignores type_ids for loss masking (LabTOP-style).\n",
        "    \"\"\"\n",
        "    def __init__(self, data_path):\n",
        "        with open(data_path, \"rb\") as f:\n",
        "            self.data = pickle.load(f)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = self.data[idx]\n",
        "        return {\n",
        "            \"input_ids\": torch.tensor(item[\"input_ids\"], dtype=torch.long),\n",
        "            \"type_ids\": torch.tensor(item[\"type_ids\"], dtype=torch.long),  # kept for potential analysis\n",
        "        }\n",
        "\n",
        "\n",
        "# ---------------- COLLATE FN ----------------\n",
        "def collate_fn(batch, pad_token_id):\n",
        "    \"\"\"\n",
        "    - Truncates to MAX_LEN (from the *right* by default)\n",
        "    - Pads to the longest length in batch\n",
        "    - Labels = input_ids shifted internally by GPT2; here we just\n",
        "      pass input_ids as labels with pad positions set to -100.\n",
        "    \"\"\"\n",
        "    input_ids = [b[\"input_ids\"] for b in batch]\n",
        "\n",
        "    # truncate sequences (keep last MAX_LEN tokens)\n",
        "    truncated = []\n",
        "    for seq in input_ids:\n",
        "        if len(seq) > MAX_LEN:\n",
        "            truncated.append(seq[-MAX_LEN:])\n",
        "        else:\n",
        "            truncated.append(seq)\n",
        "\n",
        "    input_ids_pad = torch.nn.utils.rnn.pad_sequence(\n",
        "        truncated, batch_first=True, padding_value=pad_token_id\n",
        "    )\n",
        "    attention_mask = (input_ids_pad != pad_token_id).long()\n",
        "\n",
        "    labels = input_ids_pad.clone()\n",
        "    labels[input_ids_pad == pad_token_id] = -100   # ignore pads only\n",
        "\n",
        "    return input_ids_pad, attention_mask, labels\n",
        "\n",
        "\n",
        "# ---------------- MODEL (small GPT2-style LM) ----------------\n",
        "class LabTOPGPT2Small(nn.Module):\n",
        "    \"\"\"\n",
        "    Small GPT-2 style LM:\n",
        "    - fewer layers / smaller hidden size for your budget\n",
        "    - still uses GPT2LMHeadModel for correct autoregressive behavior\n",
        "    \"\"\"\n",
        "    def __init__(self, tokenizer, d_model=256, n_heads=4, num_layers=4, max_len=MAX_LEN, dropout=0.1):\n",
        "        super().__init__()\n",
        "        vocab_size = len(tokenizer)\n",
        "        config = GPT2Config(\n",
        "            vocab_size=vocab_size,\n",
        "            n_embd=d_model,\n",
        "            n_head=n_heads,\n",
        "            n_layer=num_layers,\n",
        "            n_positions=max_len,\n",
        "            n_ctx=max_len,\n",
        "            resid_pdrop=dropout,\n",
        "            embd_pdrop=dropout,\n",
        "            attn_pdrop=dropout,\n",
        "            bos_token_id=tokenizer.bos_token_id,\n",
        "            eos_token_id=tokenizer.eos_token_id,\n",
        "        )\n",
        "        self.model = GPT2LMHeadModel(config)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask=None, labels=None):\n",
        "        \"\"\"\n",
        "        GPT2LMHeadModel will:\n",
        "        - apply causal masking internally\n",
        "        - compute next-token cross-entropy loss if labels is provided\n",
        "        \"\"\"\n",
        "        outputs = self.model(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            labels=labels,\n",
        "        )\n",
        "        return outputs  # has .logits and .loss\n",
        "\n",
        "    def generate_next_tokens(self, input_ids, attention_mask=None, max_new_tokens=6, bad_ids=None, eos_id=None):\n",
        "        \"\"\"\n",
        "        Simple greedy generation of a few tokens.\n",
        "        \"\"\"\n",
        "        self.eval()\n",
        "        device = input_ids.device\n",
        "        generated = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for _ in range(max_new_tokens):\n",
        "                if input_ids.size(1) > MAX_LEN:\n",
        "                    input_ids = input_ids[:, -MAX_LEN:]\n",
        "                    if attention_mask is not None:\n",
        "                        attention_mask = attention_mask[:, -MAX_LEN:]\n",
        "\n",
        "                outputs = self.model(input_ids, attention_mask=attention_mask)\n",
        "                logits = outputs.logits[:, -1, :]  # (B, vocab)\n",
        "                if bad_ids:\n",
        "                    logits[:, bad_ids] = -1e9\n",
        "\n",
        "                next_token = torch.argmax(logits, dim=-1)  # (B,)\n",
        "                next_id = next_token.item()\n",
        "                generated.append(next_id)\n",
        "\n",
        "                input_ids = torch.cat([input_ids, next_token.unsqueeze(0)], dim=1)\n",
        "                if attention_mask is not None:\n",
        "                    next_mask_token = torch.ones_like(next_token).unsqueeze(0)\n",
        "                    attention_mask = torch.cat([attention_mask, next_mask_token], dim=1)\n",
        "\n",
        "                if eos_id is not None and next_id == eos_id:\n",
        "                    break\n",
        "\n",
        "        return generated\n",
        "\n",
        "\n",
        "# ---------------- DECODE NUMERIC VALUE ----------------\n",
        "def decode_value(token_ids, tokenizer):\n",
        "    \"\"\"\n",
        "    Char-level decode: keep digits, '.', '-' and parse as float.\n",
        "    Returns None if parsing fails.\n",
        "    \"\"\"\n",
        "    text = tokenizer.decode(token_ids)\n",
        "    text = text.replace(\" \", \"\")\n",
        "    filtered = \"\".join(ch for ch in text if ch.isdigit() or ch in \".-\")\n",
        "    if filtered == \"\":\n",
        "        return None\n",
        "    try:\n",
        "        return float(filtered)\n",
        "    except Exception:\n",
        "        return None\n",
        "\n",
        "\n",
        "# ---------------- TRAIN ----------------\n",
        "def train_model(resume=False):\n",
        "    \"\"\"\n",
        "    完全断点续训版本：\n",
        "      - 如果 resume=True 且 CKPT_LAST 存在，则从上次保存的 epoch 继续\n",
        "      - 否则从头开始训练\n",
        "    \"\"\"\n",
        "    set_seed(42)\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f\"Using device: {device}\")\n",
        "\n",
        "    tokenizer = AutoTokenizer.from_pretrained(DATA_DIR)\n",
        "    if tokenizer.pad_token is None:\n",
        "        tokenizer.pad_token = tokenizer.eos_token\n",
        "    pad_id = tokenizer.pad_token_id\n",
        "\n",
        "    train_dataset = LabTOPDataset(os.path.join(DATA_DIR, \"train.pkl\"))\n",
        "    val_dataset   = LabTOPDataset(os.path.join(DATA_DIR, \"val.pkl\"))\n",
        "    print(\"Train dataset size:\", len(train_dataset))\n",
        "    print(\"Seq length example:\", len(train_dataset[0][\"input_ids\"]))\n",
        "\n",
        "    def collate_func(batch):\n",
        "        return collate_fn(batch, pad_token_id=pad_id)\n",
        "\n",
        "    train_loader = DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        shuffle=True,\n",
        "        collate_fn=collate_func,\n",
        "        num_workers=0,\n",
        "        pin_memory=(device.type == \"cuda\"),\n",
        "    )\n",
        "    val_loader = DataLoader(\n",
        "        val_dataset,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        shuffle=False,\n",
        "        collate_fn=collate_func,\n",
        "        num_workers=0,\n",
        "        pin_memory=(device.type == \"cuda\"),\n",
        "    )\n",
        "\n",
        "    model = LabTOPGPT2Small(tokenizer).to(device)\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=LR)\n",
        "    use_amp = (device.type == \"cuda\")\n",
        "    scaler = torch.cuda.amp.GradScaler(enabled=use_amp)\n",
        "\n",
        "    # ---- 断点恢复逻辑 ----\n",
        "    start_epoch = 0\n",
        "    best_val_loss = float(\"inf\")\n",
        "    patience_counter = 0\n",
        "\n",
        "    if resume and os.path.exists(CKPT_LAST):\n",
        "        print(f\"Resuming from checkpoint: {CKPT_LAST}\")\n",
        "        checkpoint = torch.load(CKPT_LAST, map_location=device)\n",
        "\n",
        "        model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
        "        optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
        "        scaler.load_state_dict(checkpoint[\"scaler_state_dict\"])\n",
        "\n",
        "        start_epoch      = checkpoint.get(\"epoch\", 0) + 1   # 下一个 epoch\n",
        "        best_val_loss    = checkpoint.get(\"best_val_loss\", float(\"inf\"))\n",
        "        patience_counter = checkpoint.get(\"patience_counter\", 0)\n",
        "\n",
        "        print(\n",
        "            f\"  -> start_epoch = {start_epoch}, \"\n",
        "            f\"best_val_loss = {best_val_loss:.4f}, \"\n",
        "            f\"patience_counter = {patience_counter}\"\n",
        "        )\n",
        "    else:\n",
        "        if resume:\n",
        "            print(f\"resume=True but checkpoint not found at {CKPT_LAST}, training from scratch.\")\n",
        "        else:\n",
        "            print(\"Training from scratch.\")\n",
        "\n",
        "    # ---- 训练循环 ----\n",
        "    for epoch in range(start_epoch, NUM_EPOCHS):\n",
        "        # ---------- TRAIN ----------\n",
        "        model.train()\n",
        "        total_loss = 0.0\n",
        "        count = 0\n",
        "\n",
        "        for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1} [train]\"):\n",
        "            input_ids, attention_mask, labels = [b.to(device) for b in batch]\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            with torch.cuda.amp.autocast(enabled=use_amp):\n",
        "                outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "                loss = outputs.loss\n",
        "\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.unscale_(optimizer)\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), GRAD_CLIP)\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            count += 1\n",
        "\n",
        "        avg_train_loss = total_loss / max(count, 1)\n",
        "        print(f\"Epoch {epoch+1} Train Loss: {avg_train_loss:.4f}\")\n",
        "\n",
        "        # ---------- VALIDATION ----------\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        val_count = 0\n",
        "        with torch.no_grad():\n",
        "            for batch in tqdm(val_loader, desc=f\"Epoch {epoch+1} [val]\"):\n",
        "                input_ids, attention_mask, labels = [b.to(device) for b in batch]\n",
        "                with torch.cuda.amp.autocast(enabled=use_amp):\n",
        "                    outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "                    loss = outputs.loss\n",
        "                val_loss += loss.item()\n",
        "                val_count += 1\n",
        "\n",
        "        avg_val_loss = val_loss / max(val_count, 1)\n",
        "        print(f\"Epoch {epoch+1} Val Loss: {avg_val_loss:.4f}\")\n",
        "\n",
        "        # ---------- 保存最优模型（仅参数，用于 eval） ----------\n",
        "        if avg_val_loss < best_val_loss:\n",
        "            best_val_loss = avg_val_loss\n",
        "            patience_counter = 0\n",
        "            torch.save(model.state_dict(), CKPT_BEST)\n",
        "            print(f\"Saved BEST model (val loss={best_val_loss:.4f}) to {CKPT_BEST}\")\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "            print(f\"No improvement. Patience: {patience_counter}/{PATIENCE}\")\n",
        "\n",
        "        # ---------- 保存完整断点（每个 epoch 都保存） ----------\n",
        "        last_state = {\n",
        "            \"epoch\": epoch,\n",
        "            \"model_state_dict\": model.state_dict(),\n",
        "            \"optimizer_state_dict\": optimizer.state_dict(),\n",
        "            \"scaler_state_dict\": scaler.state_dict(),\n",
        "            \"best_val_loss\": best_val_loss,\n",
        "            \"patience_counter\": patience_counter,\n",
        "        }\n",
        "        torch.save(last_state, CKPT_LAST)\n",
        "        print(f\"Saved training checkpoint to {CKPT_LAST}\")\n",
        "\n",
        "        # ---------- EARLY STOP ----------\n",
        "        if patience_counter >= PATIENCE:\n",
        "            print(\"Early stopping triggered.\")\n",
        "            break\n",
        "\n",
        "    print(\"Training complete.\")\n",
        "\n",
        "\n",
        "# ---------------- EVALUATION ----------------\n",
        "def evaluate_model(resume=False, save_every=10000):\n",
        "    test_eval_path = os.path.join(DATA_DIR, \"test_eval.pkl\")\n",
        "\n",
        "    if not os.path.exists(test_eval_path):\n",
        "        print(\"test_eval.pkl not found; nothing to evaluate.\")\n",
        "        return\n",
        "    if not os.path.exists(CKPT_BEST):\n",
        "        print(f\"Best model checkpoint {CKPT_BEST} not found; train first.\")\n",
        "        return\n",
        "\n",
        "    # 进度文件，用来断点续 eval\n",
        "    PROGRESS_PATH = os.path.join(DATA_DIR, \"eval_progress.pkl\")\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        device = torch.device(\"cuda\")\n",
        "    elif torch.backends.mps.is_available():\n",
        "        device = torch.device(\"mps\")\n",
        "    else:\n",
        "        device = torch.device(\"cpu\")\n",
        "    print(f\"Using device: {device}\")\n",
        "\n",
        "    tokenizer = AutoTokenizer.from_pretrained(DATA_DIR)\n",
        "    if tokenizer.pad_token is None:\n",
        "        tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "    with open(test_eval_path, \"rb\") as f:\n",
        "        test_data = pickle.load(f)\n",
        "    print(f\"Total examples in test_eval: {len(test_data)}\")\n",
        "\n",
        "    model = LabTOPGPT2Small(tokenizer).to(device)\n",
        "    model.load_state_dict(torch.load(CKPT_BEST, map_location=device))\n",
        "    model.eval()\n",
        "\n",
        "    use_amp = (device.type == \"cuda\")\n",
        "\n",
        "    # tokens we never want as value predictions\n",
        "    bad_tokens = [\n",
        "        \"labevent\", \"inputevent\", \"outputevent\",\n",
        "        \"gender\", \"age\", \"race\",\n",
        "        \"procedureevent\", \"emarevent\", \"microevent\"\n",
        "    ]\n",
        "    vocab = tokenizer.get_vocab()\n",
        "    bad_ids = [tokenizer.convert_tokens_to_ids(t) for t in bad_tokens if t in vocab]\n",
        "\n",
        "    eoe_id = tokenizer.convert_tokens_to_ids(\"[EOE]\")\n",
        "    max_new_tokens = 6\n",
        "\n",
        "    # --------- 恢复 / 初始化进度 ---------\n",
        "    if resume and os.path.exists(PROGRESS_PATH):\n",
        "        print(f\"Resuming evaluation from {PROGRESS_PATH}\")\n",
        "        prog = pickle.load(open(PROGRESS_PATH, \"rb\"))\n",
        "        predictions     = prog[\"predictions\"]\n",
        "        ground_truths   = prog[\"ground_truths\"]\n",
        "        itemids         = prog[\"itemids\"]\n",
        "        event_types     = prog[\"event_types\"]\n",
        "        example_indices = prog[\"example_indices\"]\n",
        "        start_idx       = prog[\"next_idx\"]\n",
        "    else:\n",
        "        predictions     = []\n",
        "        ground_truths   = []\n",
        "        itemids         = []\n",
        "        event_types     = []\n",
        "        example_indices = []\n",
        "        start_idx       = 0\n",
        "\n",
        "    print(f\"Start evaluating from index {start_idx} ...\")\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    for idx in tqdm(range(start_idx, len(test_data)), desc=\"Evaluating\"):\n",
        "        item = test_data[idx]\n",
        "        prompt_ids = item[\"prompt_ids\"]\n",
        "        true_val   = item[\"valuenum\"]\n",
        "        itemid     = item.get(\"itemid\", None)\n",
        "        e_type     = item.get(\"event_type\", \"unknown\")\n",
        "\n",
        "        # truncate prompt from the left to MAX_LEN\n",
        "        if len(prompt_ids) > MAX_LEN:\n",
        "            prompt_ids = prompt_ids[-MAX_LEN:]\n",
        "\n",
        "        input_tensor = torch.tensor([prompt_ids], dtype=torch.long).to(device)\n",
        "        attn_mask    = torch.ones_like(input_tensor, dtype=torch.long).to(device)\n",
        "\n",
        "        # 只前几个样本打印 debug\n",
        "        if idx < start_idx + 3:\n",
        "            decoded_prompt_tail = tokenizer.decode(prompt_ids[-80:])\n",
        "            print(f\"\\n=== Debug sample {idx} ===\")\n",
        "            print(f\"Prompt tail: {decoded_prompt_tail}\")\n",
        "            print(f\"True value: {true_val}, itemid: {itemid}, event_type: {e_type}\")\n",
        "\n",
        "        with torch.no_grad():\n",
        "            with torch.cuda.amp.autocast(enabled=use_amp):\n",
        "                generated_ids = model.generate_next_tokens(\n",
        "                    input_ids=input_tensor,\n",
        "                    attention_mask=attn_mask,\n",
        "                    max_new_tokens=max_new_tokens,\n",
        "                    bad_ids=bad_ids,\n",
        "                    eos_id=eoe_id,\n",
        "                )\n",
        "\n",
        "        pred_val = decode_value(generated_ids, tokenizer)\n",
        "        if pred_val is None or not isfinite(pred_val) or abs(pred_val) > 1e4:\n",
        "            # 无效预测，跳过但仍然推进 idx\n",
        "            continue\n",
        "\n",
        "        if idx < start_idx + 3:\n",
        "            decoded_generated = tokenizer.decode(generated_ids)\n",
        "            print(f\"Generated tokens: {decoded_generated}\")\n",
        "            print(f\"Decoded pred_val: {pred_val}\")\n",
        "\n",
        "        predictions.append(pred_val)\n",
        "        ground_truths.append(true_val)\n",
        "        itemids.append(itemid)\n",
        "        event_types.append(e_type)\n",
        "        example_indices.append(idx)\n",
        "\n",
        "        # --------- 定期保存 eval 进度 ---------\n",
        "        if (idx + 1) % save_every == 0:\n",
        "            prog = {\n",
        "                \"predictions\": predictions,\n",
        "                \"ground_truths\": ground_truths,\n",
        "                \"itemids\": itemids,\n",
        "                \"event_types\": event_types,\n",
        "                \"example_indices\": example_indices,\n",
        "                \"next_idx\": idx + 1,  # 下次从这里继续\n",
        "            }\n",
        "            with open(PROGRESS_PATH, \"wb\") as f:\n",
        "                pickle.dump(prog, f)\n",
        "            print(f\"\\n[Checkpoint] Saved eval progress at idx={idx+1} -> {PROGRESS_PATH}\")\n",
        "\n",
        "    # 全部跑完，删除进度文件\n",
        "    if os.path.exists(PROGRESS_PATH):\n",
        "        os.remove(PROGRESS_PATH)\n",
        "        print(f\"Removed eval progress file {PROGRESS_PATH}\")\n",
        "\n",
        "    if len(predictions) == 0:\n",
        "        print(\"No valid predictions generated.\")\n",
        "        return\n",
        "\n",
        "    preds  = np.array(predictions)\n",
        "    truths = np.array(ground_truths)\n",
        "\n",
        "    mae  = np.mean(np.abs(preds - truths))\n",
        "    rmse = np.sqrt(np.mean((preds - truths) ** 2))\n",
        "\n",
        "    p1   = np.percentile(truths, 1)\n",
        "    p99  = np.percentile(truths, 99)\n",
        "    range_val = p99 - p1 if p99 > p1 else 1e-6\n",
        "    nmae = mae / range_val\n",
        "\n",
        "    denom = (np.abs(truths) + np.abs(preds))\n",
        "    mask = denom > 0\n",
        "    if np.sum(mask) > 0:\n",
        "        smape = np.mean(2 * np.abs(preds[mask] - truths[mask]) / denom[mask])\n",
        "    else:\n",
        "        smape = 0.0\n",
        "\n",
        "    elapsed = time.time() - start_time\n",
        "    print(f\"\\nEvaluated {len(preds)} samples in {elapsed:.2f} seconds.\")\n",
        "    print(f\"Test MAE:   {mae:.4f}\")\n",
        "    print(f\"Test RMSE:  {rmse:.4f}\")\n",
        "    print(f\"Test NMAE:  {nmae:.4f}\")\n",
        "    print(f\"Test SMAPE: {smape:.4f}\")\n",
        "\n",
        "    # 保存 sample predictions\n",
        "    csv_path = os.path.join(DATA_DIR, \"test_predictions.csv\")\n",
        "    print(f\"Saving predictions to: {csv_path}\")\n",
        "    import csv\n",
        "    with open(csv_path, \"w\", newline=\"\") as f:\n",
        "        writer = csv.writer(f)\n",
        "        writer.writerow([\"index\", \"itemid\", \"event_type\", \"true_value\", \"pred_value\"])\n",
        "        for i, iid, et, truth, pred in zip(example_indices, itemids, event_types, truths, preds):\n",
        "            writer.writerow([i, iid, et, truth, pred])\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # 训练\n",
        "    # RESUME_TRAIN = False\n",
        "    # train_model(resume=RESUME_TRAIN)\n",
        "\n",
        "    # eval：第一次跑用 resume=False，之后断了想接着跑就改成 True\n",
        "    RESUME_EVAL = False\n",
        "    evaluate_model(resume=RESUME_EVAL)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "import pickle\n",
        "import random\n",
        "import numpy as np\n",
        "from math import isfinite\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from tqdm import tqdm\n",
        "from transformers import AutoTokenizer, GPT2Config, GPT2LMHeadModel\n",
        "\n",
        "# ---------------- CONFIG ----------------\n",
        "DATA_DIR = \"/content/drive/MyDrive/labtop2/v1\"  # <-- adjust\n",
        "MAX_LEN = 1024            # must be <= preprocessor max_len\n",
        "BATCH_SIZE = 32\n",
        "LR = 5e-4                 # a bit higher for small model\n",
        "NUM_EPOCHS = 10\n",
        "PATIENCE = 3\n",
        "GRAD_CLIP = 1.0\n",
        "\n",
        "# checkpoint 路径\n",
        "CKPT_LAST = os.path.join(DATA_DIR, \"labtop_checkpoint_last.pt\")  # 断点续训用\n",
        "CKPT_BEST = os.path.join(DATA_DIR, \"labtop_v1.pth\")      # 最优模型，用于 eval\n",
        "\n",
        "\n",
        "# ---------------- UTILS ----------------\n",
        "def set_seed(seed=42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "\n",
        "# ---------------- DATASET ----------------\n",
        "class LabTOPDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Uses only input_ids/type_ids from your preprocessed pkl.\n",
        "    Training now ignores type_ids for loss masking (LabTOP-style).\n",
        "    \"\"\"\n",
        "    def __init__(self, data_path):\n",
        "        with open(data_path, \"rb\") as f:\n",
        "            self.data = pickle.load(f)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = self.data[idx]\n",
        "        return {\n",
        "            \"input_ids\": torch.tensor(item[\"input_ids\"], dtype=torch.long),\n",
        "            \"type_ids\": torch.tensor(item[\"type_ids\"], dtype=torch.long),  # kept for potential analysis\n",
        "        }\n",
        "\n",
        "\n",
        "# ---------------- COLLATE FN ----------------\n",
        "def collate_fn(batch, pad_token_id):\n",
        "    \"\"\"\n",
        "    - Truncates to MAX_LEN (from the *right* by default)\n",
        "    - Pads to the longest length in batch\n",
        "    - Labels = input_ids shifted internally by GPT2; here we just\n",
        "      pass input_ids as labels with pad positions set to -100.\n",
        "    \"\"\"\n",
        "    input_ids = [b[\"input_ids\"] for b in batch]\n",
        "\n",
        "    # truncate sequences (keep last MAX_LEN tokens)\n",
        "    truncated = []\n",
        "    for seq in input_ids:\n",
        "        if len(seq) > MAX_LEN:\n",
        "            truncated.append(seq[-MAX_LEN:])\n",
        "        else:\n",
        "            truncated.append(seq)\n",
        "\n",
        "    input_ids_pad = torch.nn.utils.rnn.pad_sequence(\n",
        "        truncated, batch_first=True, padding_value=pad_token_id\n",
        "    )\n",
        "    attention_mask = (input_ids_pad != pad_token_id).long()\n",
        "\n",
        "    labels = input_ids_pad.clone()\n",
        "    labels[input_ids_pad == pad_token_id] = -100   # ignore pads only\n",
        "\n",
        "    return input_ids_pad, attention_mask, labels\n",
        "\n",
        "\n",
        "# ---------------- MODEL (small GPT2-style LM) ----------------\n",
        "class LabTOPGPT2Small(nn.Module):\n",
        "    \"\"\"\n",
        "    Small GPT-2 style LM:\n",
        "    - fewer layers / smaller hidden size for your budget\n",
        "    - still uses GPT2LMHeadModel for correct autoregressive behavior\n",
        "    \"\"\"\n",
        "    def __init__(self, tokenizer, d_model=256, n_heads=4, num_layers=4, max_len=MAX_LEN, dropout=0.1):\n",
        "        super().__init__()\n",
        "        vocab_size = len(tokenizer)\n",
        "        config = GPT2Config(\n",
        "            vocab_size=vocab_size,\n",
        "            n_embd=d_model,\n",
        "            n_head=n_heads,\n",
        "            n_layer=num_layers,\n",
        "            n_positions=max_len,\n",
        "            n_ctx=max_len,\n",
        "            resid_pdrop=dropout,\n",
        "            embd_pdrop=dropout,\n",
        "            attn_pdrop=dropout,\n",
        "            bos_token_id=tokenizer.bos_token_id,\n",
        "            eos_token_id=tokenizer.eos_token_id,\n",
        "        )\n",
        "        self.model = GPT2LMHeadModel(config)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask=None, labels=None):\n",
        "        \"\"\"\n",
        "        GPT2LMHeadModel will:\n",
        "        - apply causal masking internally\n",
        "        - compute next-token cross-entropy loss if labels is provided\n",
        "        \"\"\"\n",
        "        outputs = self.model(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            labels=labels,\n",
        "        )\n",
        "        return outputs  # has .logits and .loss\n",
        "\n",
        "    def generate_next_tokens(self, input_ids, attention_mask=None, max_new_tokens=6, bad_ids=None, eos_id=None):\n",
        "        \"\"\"\n",
        "        Simple greedy generation of a few tokens.\n",
        "        \"\"\"\n",
        "        self.eval()\n",
        "        device = input_ids.device\n",
        "        generated = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for _ in range(max_new_tokens):\n",
        "                if input_ids.size(1) > MAX_LEN:\n",
        "                    input_ids = input_ids[:, -MAX_LEN:]\n",
        "                    if attention_mask is not None:\n",
        "                        attention_mask = attention_mask[:, -MAX_LEN:]\n",
        "\n",
        "                outputs = self.model(input_ids, attention_mask=attention_mask)\n",
        "                logits = outputs.logits[:, -1, :]  # (B, vocab)\n",
        "                if bad_ids:\n",
        "                    logits[:, bad_ids] = -1e9\n",
        "\n",
        "                next_token = torch.argmax(logits, dim=-1)  # (B,)\n",
        "                next_id = next_token.item()\n",
        "                generated.append(next_id)\n",
        "\n",
        "                input_ids = torch.cat([input_ids, next_token.unsqueeze(0)], dim=1)\n",
        "                if attention_mask is not None:\n",
        "                    next_mask_token = torch.ones_like(next_token).unsqueeze(0)\n",
        "                    attention_mask = torch.cat([attention_mask, next_mask_token], dim=1)\n",
        "\n",
        "                if eos_id is not None and next_id == eos_id:\n",
        "                    break\n",
        "\n",
        "        return generated\n",
        "\n",
        "\n",
        "# ---------------- DECODE NUMERIC VALUE ----------------\n",
        "def decode_value(token_ids, tokenizer):\n",
        "    \"\"\"\n",
        "    Char-level decode: keep digits, '.', '-' and parse as float.\n",
        "    Returns None if parsing fails.\n",
        "    \"\"\"\n",
        "    text = tokenizer.decode(token_ids)\n",
        "    text = text.replace(\" \", \"\")\n",
        "    filtered = \"\".join(ch for ch in text if ch.isdigit() or ch in \".-\")\n",
        "    if filtered == \"\":\n",
        "        return None\n",
        "    try:\n",
        "        return float(filtered)\n",
        "    except Exception:\n",
        "        return None\n",
        "\n",
        "\n",
        "# ---------------- TRAIN ----------------\n",
        "def train_model(resume=False):\n",
        "    \"\"\"\n",
        "    完全断点续训版本：\n",
        "      - 如果 resume=True 且 CKPT_LAST 存在，则从上次保存的 epoch 继续\n",
        "      - 否则从头开始训练\n",
        "    \"\"\"\n",
        "    set_seed(42)\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f\"Using device: {device}\")\n",
        "\n",
        "    tokenizer = AutoTokenizer.from_pretrained(DATA_DIR)\n",
        "    if tokenizer.pad_token is None:\n",
        "        tokenizer.pad_token = tokenizer.eos_token\n",
        "    pad_id = tokenizer.pad_token_id\n",
        "\n",
        "    train_dataset = LabTOPDataset(os.path.join(DATA_DIR, \"train.pkl\"))\n",
        "    val_dataset   = LabTOPDataset(os.path.join(DATA_DIR, \"val.pkl\"))\n",
        "    print(\"Train dataset size:\", len(train_dataset))\n",
        "    print(\"Seq length example:\", len(train_dataset[0][\"input_ids\"]))\n",
        "\n",
        "    def collate_func(batch):\n",
        "        return collate_fn(batch, pad_token_id=pad_id)\n",
        "\n",
        "    train_loader = DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        shuffle=True,\n",
        "        collate_fn=collate_func,\n",
        "        num_workers=0,\n",
        "        pin_memory=(device.type == \"cuda\"),\n",
        "    )\n",
        "    val_loader = DataLoader(\n",
        "        val_dataset,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        shuffle=False,\n",
        "        collate_fn=collate_func,\n",
        "        num_workers=0,\n",
        "        pin_memory=(device.type == \"cuda\"),\n",
        "    )\n",
        "\n",
        "    model = LabTOPGPT2Small(tokenizer).to(device)\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=LR)\n",
        "    use_amp = (device.type == \"cuda\")\n",
        "    scaler = torch.cuda.amp.GradScaler(enabled=use_amp)\n",
        "\n",
        "    # ---- 断点恢复逻辑 ----\n",
        "    start_epoch = 0\n",
        "    best_val_loss = float(\"inf\")\n",
        "    patience_counter = 0\n",
        "\n",
        "    if resume and os.path.exists(CKPT_LAST):\n",
        "        print(f\"Resuming from checkpoint: {CKPT_LAST}\")\n",
        "        checkpoint = torch.load(CKPT_LAST, map_location=device)\n",
        "\n",
        "        model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
        "        optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
        "        scaler.load_state_dict(checkpoint[\"scaler_state_dict\"])\n",
        "\n",
        "        start_epoch      = checkpoint.get(\"epoch\", 0) + 1   # 下一个 epoch\n",
        "        best_val_loss    = checkpoint.get(\"best_val_loss\", float(\"inf\"))\n",
        "        patience_counter = checkpoint.get(\"patience_counter\", 0)\n",
        "\n",
        "        print(\n",
        "            f\"  -> start_epoch = {start_epoch}, \"\n",
        "            f\"best_val_loss = {best_val_loss:.4f}, \"\n",
        "            f\"patience_counter = {patience_counter}\"\n",
        "        )\n",
        "    else:\n",
        "        if resume:\n",
        "            print(f\"resume=True but checkpoint not found at {CKPT_LAST}, training from scratch.\")\n",
        "        else:\n",
        "            print(\"Training from scratch.\")\n",
        "\n",
        "    # ---- 训练循环 ----\n",
        "    for epoch in range(start_epoch, NUM_EPOCHS):\n",
        "        # ---------- TRAIN ----------\n",
        "        model.train()\n",
        "        total_loss = 0.0\n",
        "        count = 0\n",
        "\n",
        "        for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1} [train]\"):\n",
        "            input_ids, attention_mask, labels = [b.to(device) for b in batch]\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            with torch.cuda.amp.autocast(enabled=use_amp):\n",
        "                outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "                loss = outputs.loss\n",
        "\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.unscale_(optimizer)\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), GRAD_CLIP)\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            count += 1\n",
        "\n",
        "        avg_train_loss = total_loss / max(count, 1)\n",
        "        print(f\"Epoch {epoch+1} Train Loss: {avg_train_loss:.4f}\")\n",
        "\n",
        "        # ---------- VALIDATION ----------\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        val_count = 0\n",
        "        with torch.no_grad():\n",
        "            for batch in tqdm(val_loader, desc=f\"Epoch {epoch+1} [val]\"):\n",
        "                input_ids, attention_mask, labels = [b.to(device) for b in batch]\n",
        "                with torch.cuda.amp.autocast(enabled=use_amp):\n",
        "                    outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "                    loss = outputs.loss\n",
        "                val_loss += loss.item()\n",
        "                val_count += 1\n",
        "\n",
        "        avg_val_loss = val_loss / max(val_count, 1)\n",
        "        print(f\"Epoch {epoch+1} Val Loss: {avg_val_loss:.4f}\")\n",
        "\n",
        "        # ---------- 保存最优模型（仅参数，用于 eval） ----------\n",
        "        if avg_val_loss < best_val_loss:\n",
        "            best_val_loss = avg_val_loss\n",
        "            patience_counter = 0\n",
        "            torch.save(model.state_dict(), CKPT_BEST)\n",
        "            print(f\"Saved BEST model (val loss={best_val_loss:.4f}) to {CKPT_BEST}\")\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "            print(f\"No improvement. Patience: {patience_counter}/{PATIENCE}\")\n",
        "\n",
        "        # ---------- 保存完整断点（每个 epoch 都保存） ----------\n",
        "        last_state = {\n",
        "            \"epoch\": epoch,\n",
        "            \"model_state_dict\": model.state_dict(),\n",
        "            \"optimizer_state_dict\": optimizer.state_dict(),\n",
        "            \"scaler_state_dict\": scaler.state_dict(),\n",
        "            \"best_val_loss\": best_val_loss,\n",
        "            \"patience_counter\": patience_counter,\n",
        "        }\n",
        "        torch.save(last_state, CKPT_LAST)\n",
        "        print(f\"Saved training checkpoint to {CKPT_LAST}\")\n",
        "\n",
        "        # ---------- EARLY STOP ----------\n",
        "        if patience_counter >= PATIENCE:\n",
        "            print(\"Early stopping triggered.\")\n",
        "            break\n",
        "\n",
        "    print(\"Training complete.\")\n",
        "\n",
        "\n",
        "# ---------------- EVALUATION ----------------\n",
        "def evaluate_model(resume=False, save_every=10000):\n",
        "    test_eval_path = os.path.join(DATA_DIR, \"test_eval.pkl\")\n",
        "\n",
        "    if not os.path.exists(test_eval_path):\n",
        "        print(\"test_eval.pkl not found; nothing to evaluate.\")\n",
        "        return\n",
        "    if not os.path.exists(CKPT_BEST):\n",
        "        print(f\"Best model checkpoint {CKPT_BEST} not found; train first.\")\n",
        "        return\n",
        "\n",
        "    # 进度文件，用来断点续 eval\n",
        "    PROGRESS_PATH = os.path.join(DATA_DIR, \"eval_progress.pkl\")\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        device = torch.device(\"cuda\")\n",
        "    elif torch.backends.mps.is_available():\n",
        "        device = torch.device(\"mps\")\n",
        "    else:\n",
        "        device = torch.device(\"cpu\")\n",
        "    print(f\"Using device: {device}\")\n",
        "\n",
        "    tokenizer = AutoTokenizer.from_pretrained(DATA_DIR)\n",
        "    if tokenizer.pad_token is None:\n",
        "        tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "    with open(test_eval_path, \"rb\") as f:\n",
        "        test_data = pickle.load(f)\n",
        "    print(f\"Total examples in test_eval: {len(test_data)}\")\n",
        "\n",
        "    model = LabTOPGPT2Small(tokenizer).to(device)\n",
        "    model.load_state_dict(torch.load(CKPT_BEST, map_location=device))\n",
        "    model.eval()\n",
        "\n",
        "    use_amp = (device.type == \"cuda\")\n",
        "\n",
        "    # tokens we never want as value predictions\n",
        "    bad_tokens = [\n",
        "        \"labevent\", \"inputevent\", \"outputevent\",\n",
        "        \"gender\", \"age\", \"race\",\n",
        "        \"procedureevent\", \"emarevent\", \"microevent\"\n",
        "    ]\n",
        "    vocab = tokenizer.get_vocab()\n",
        "    bad_ids = [tokenizer.convert_tokens_to_ids(t) for t in bad_tokens if t in vocab]\n",
        "\n",
        "    eoe_id = tokenizer.convert_tokens_to_ids(\"[EOE]\")\n",
        "    max_new_tokens = 6\n",
        "\n",
        "    # --------- 恢复 / 初始化进度 ---------\n",
        "    if resume and os.path.exists(PROGRESS_PATH):\n",
        "        print(f\"Resuming evaluation from {PROGRESS_PATH}\")\n",
        "        prog = pickle.load(open(PROGRESS_PATH, \"rb\"))\n",
        "        predictions     = prog[\"predictions\"]\n",
        "        ground_truths   = prog[\"ground_truths\"]\n",
        "        itemids         = prog[\"itemids\"]\n",
        "        event_types     = prog[\"event_types\"]\n",
        "        example_indices = prog[\"example_indices\"]\n",
        "        start_idx       = prog[\"next_idx\"]\n",
        "    else:\n",
        "        predictions     = []\n",
        "        ground_truths   = []\n",
        "        itemids         = []\n",
        "        event_types     = []\n",
        "        example_indices = []\n",
        "        start_idx       = 0\n",
        "\n",
        "    print(f\"Start evaluating from index {start_idx} ...\")\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    for idx in tqdm(range(start_idx, len(test_data)), desc=\"Evaluating\"):\n",
        "        item = test_data[idx]\n",
        "        prompt_ids = item[\"prompt_ids\"]\n",
        "        true_val   = item[\"valuenum\"]\n",
        "        itemid     = item.get(\"itemid\", None)\n",
        "        e_type     = item.get(\"event_type\", \"unknown\")\n",
        "\n",
        "        # truncate prompt from the left to MAX_LEN\n",
        "        if len(prompt_ids) > MAX_LEN:\n",
        "            prompt_ids = prompt_ids[-MAX_LEN:]\n",
        "\n",
        "        input_tensor = torch.tensor([prompt_ids], dtype=torch.long).to(device)\n",
        "        attn_mask    = torch.ones_like(input_tensor, dtype=torch.long).to(device)\n",
        "\n",
        "        # 只前几个样本打印 debug\n",
        "        if idx < start_idx + 3:\n",
        "            decoded_prompt_tail = tokenizer.decode(prompt_ids[-80:])\n",
        "            print(f\"\\n=== Debug sample {idx} ===\")\n",
        "            print(f\"Prompt tail: {decoded_prompt_tail}\")\n",
        "            print(f\"True value: {true_val}, itemid: {itemid}, event_type: {e_type}\")\n",
        "\n",
        "        with torch.no_grad():\n",
        "            with torch.cuda.amp.autocast(enabled=use_amp):\n",
        "                generated_ids = model.generate_next_tokens(\n",
        "                    input_ids=input_tensor,\n",
        "                    attention_mask=attn_mask,\n",
        "                    max_new_tokens=max_new_tokens,\n",
        "                    bad_ids=bad_ids,\n",
        "                    eos_id=eoe_id,\n",
        "                )\n",
        "\n",
        "        pred_val = decode_value(generated_ids, tokenizer)\n",
        "        if pred_val is None or not isfinite(pred_val) or abs(pred_val) > 1e4:\n",
        "            # 无效预测，跳过但仍然推进 idx\n",
        "            continue\n",
        "\n",
        "        if idx < start_idx + 3:\n",
        "            decoded_generated = tokenizer.decode(generated_ids)\n",
        "            print(f\"Generated tokens: {decoded_generated}\")\n",
        "            print(f\"Decoded pred_val: {pred_val}\")\n",
        "\n",
        "        predictions.append(pred_val)\n",
        "        ground_truths.append(true_val)\n",
        "        itemids.append(itemid)\n",
        "        event_types.append(e_type)\n",
        "        example_indices.append(idx)\n",
        "\n",
        "        # --------- 定期保存 eval 进度 ---------\n",
        "        if (idx + 1) % save_every == 0:\n",
        "            prog = {\n",
        "                \"predictions\": predictions,\n",
        "                \"ground_truths\": ground_truths,\n",
        "                \"itemids\": itemids,\n",
        "                \"event_types\": event_types,\n",
        "                \"example_indices\": example_indices,\n",
        "                \"next_idx\": idx + 1,  # 下次从这里继续\n",
        "            }\n",
        "            with open(PROGRESS_PATH, \"wb\") as f:\n",
        "                pickle.dump(prog, f)\n",
        "            print(f\"\\n[Checkpoint] Saved eval progress at idx={idx+1} -> {PROGRESS_PATH}\")\n",
        "\n",
        "    # 全部跑完，删除进度文件\n",
        "    if os.path.exists(PROGRESS_PATH):\n",
        "        os.remove(PROGRESS_PATH)\n",
        "        print(f\"Removed eval progress file {PROGRESS_PATH}\")\n",
        "\n",
        "    if len(predictions) == 0:\n",
        "        print(\"No valid predictions generated.\")\n",
        "        return\n",
        "\n",
        "    preds  = np.array(predictions)\n",
        "    truths = np.array(ground_truths)\n",
        "\n",
        "    mae  = np.mean(np.abs(preds - truths))\n",
        "    rmse = np.sqrt(np.mean((preds - truths) ** 2))\n",
        "\n",
        "    p1   = np.percentile(truths, 1)\n",
        "    p99  = np.percentile(truths, 99)\n",
        "    range_val = p99 - p1 if p99 > p1 else 1e-6\n",
        "    nmae = mae / range_val\n",
        "\n",
        "    denom = (np.abs(truths) + np.abs(preds))\n",
        "    mask = denom > 0\n",
        "    if np.sum(mask) > 0:\n",
        "        smape = np.mean(2 * np.abs(preds[mask] - truths[mask]) / denom[mask])\n",
        "    else:\n",
        "        smape = 0.0\n",
        "\n",
        "    elapsed = time.time() - start_time\n",
        "    print(f\"\\nEvaluated {len(preds)} samples in {elapsed:.2f} seconds.\")\n",
        "    print(f\"Test MAE:   {mae:.4f}\")\n",
        "    print(f\"Test RMSE:  {rmse:.4f}\")\n",
        "    print(f\"Test NMAE:  {nmae:.4f}\")\n",
        "    print(f\"Test SMAPE: {smape:.4f}\")\n",
        "\n",
        "    # 保存 sample predictions\n",
        "    csv_path = os.path.join(DATA_DIR, \"test_predictions.csv\")\n",
        "    print(f\"Saving predictions to: {csv_path}\")\n",
        "    import csv\n",
        "    with open(csv_path, \"w\", newline=\"\") as f:\n",
        "        writer = csv.writer(f)\n",
        "        writer.writerow([\"index\", \"itemid\", \"event_type\", \"true_value\", \"pred_value\"])\n",
        "        for i, iid, et, truth, pred in zip(example_indices, itemids, event_types, truths, preds):\n",
        "            writer.writerow([i, iid, et, truth, pred])\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # 训练\n",
        "    # RESUME_TRAIN = False\n",
        "    # train_model(resume=RESUME_TRAIN)\n",
        "\n",
        "    # eval：第一次跑用 resume=False，之后断了想接着跑就改成 True\n",
        "    RESUME_EVAL = True\n",
        "    evaluate_model(resume=RESUME_EVAL)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rgyLEE3F90DE",
        "outputId": "af36203f-e2d5-4202-dcf6-4608db1c516e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Total examples in test_eval: 1229791\n",
            "Resuming evaluation from /content/drive/MyDrive/labtop2/v1/eval_progress.pkl\n",
            "Start evaluating from index 970000 ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   0%|          | 0/259791 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Debug sample 970000 ===\n",
            "Prompt tail: [10m] labevent bicarbonate 2 1 meq / l [EOE] [DAY0] [SUN] [09h] [10m] labevent anion gap 1 7 meq / l [EOE] [DAY0] [SUN] [09h] [10m] labevent potassium 4 meq / l [EOE] [DAY0] [SUN] [09h] [10m] labevent troponin t 0. 0 5 ng / ml [EOE] [DAY0] [SUN] [09h] [10m] labevent urea nitrogen 5 4 mg / dl [EOE] [DAY0] [SUN] [09h] [10m] labevent sodium\n",
            "True value: 146.0, itemid: 50983, event_type: labevent\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-953783249.py:417: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=use_amp):\n",
            "Evaluating:   0%|          | 4/259791 [00:00<11:45:50,  6.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated tokens: 1 4 1 meq /\n",
            "Decoded pred_val: 141.0\n",
            "\n",
            "=== Debug sample 970001 ===\n",
            "Prompt tail: ##roponin t 0. 0 5 ng / ml [EOE] [DAY0] [SUN] [09h] [10m] labevent urea nitrogen 5 4 mg / dl [EOE] [DAY0] [SUN] [09h] [10m] labevent sodium 1 4 6 meq / l [EOE] [DAY0] [SUN] [09h] [20m] inputevent solution 1 1. 1 7 ml [EOE] [DAY0] [SUN] [09h] [20m] inputevent propofol 1 1 1. 7 2 mg [EOE] [DAY0] [SUN] [09h] [20m] labevent oxygen saturation\n",
            "True value: 97.0, itemid: 50817, event_type: labevent\n",
            "Generated tokens: 9 8 % [EOE]\n",
            "Decoded pred_val: 98.0\n",
            "\n",
            "=== Debug sample 970002 ===\n",
            "Prompt tail: ##l [EOE] [DAY0] [SUN] [09h] [10m] labevent urea nitrogen 5 4 mg / dl [EOE] [DAY0] [SUN] [09h] [10m] labevent sodium 1 4 6 meq / l [EOE] [DAY0] [SUN] [09h] [20m] inputevent solution 1 1. 1 7 ml [EOE] [DAY0] [SUN] [09h] [20m] inputevent propofol 1 1 1. 7 2 mg [EOE] [DAY0] [SUN] [09h] [20m] labevent oxygen saturation 9 7 % [EOE] [DAY0] [SUN] [09h] [20m] labevent free calcium\n",
            "True value: 1.13, itemid: 50808, event_type: labevent\n",
            "Generated tokens: 1. 1 2 mmol\n",
            "Decoded pred_val: 1.12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating:   4%|▍         | 10007/259791 [04:30<2:40:07, 26.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Checkpoint] Saved eval progress at idx=980000 -> /content/drive/MyDrive/labtop2/v1/eval_progress.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating:   8%|▊         | 20006/259791 [08:59<2:43:22, 24.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Checkpoint] Saved eval progress at idx=990000 -> /content/drive/MyDrive/labtop2/v1/eval_progress.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating:  12%|█▏        | 30007/259791 [13:26<2:26:11, 26.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Checkpoint] Saved eval progress at idx=1000000 -> /content/drive/MyDrive/labtop2/v1/eval_progress.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating:  15%|█▌        | 40007/259791 [17:55<2:19:32, 26.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Checkpoint] Saved eval progress at idx=1010000 -> /content/drive/MyDrive/labtop2/v1/eval_progress.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating:  19%|█▉        | 50005/259791 [22:23<2:04:29, 28.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Checkpoint] Saved eval progress at idx=1020000 -> /content/drive/MyDrive/labtop2/v1/eval_progress.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating:  23%|██▎       | 60003/259791 [26:52<2:32:37, 21.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Checkpoint] Saved eval progress at idx=1030000 -> /content/drive/MyDrive/labtop2/v1/eval_progress.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating:  27%|██▋       | 70003/259791 [31:17<2:25:20, 21.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Checkpoint] Saved eval progress at idx=1040000 -> /content/drive/MyDrive/labtop2/v1/eval_progress.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating:  31%|███       | 80006/259791 [35:43<1:58:55, 25.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Checkpoint] Saved eval progress at idx=1050000 -> /content/drive/MyDrive/labtop2/v1/eval_progress.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating:  35%|███▍      | 90005/259791 [40:10<1:59:29, 23.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Checkpoint] Saved eval progress at idx=1060000 -> /content/drive/MyDrive/labtop2/v1/eval_progress.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating:  38%|███▊      | 100005/259791 [44:37<1:43:41, 25.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Checkpoint] Saved eval progress at idx=1070000 -> /content/drive/MyDrive/labtop2/v1/eval_progress.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating:  42%|████▏     | 110008/259791 [49:05<1:31:07, 27.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Checkpoint] Saved eval progress at idx=1080000 -> /content/drive/MyDrive/labtop2/v1/eval_progress.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating:  46%|████▌     | 120007/259791 [53:34<1:33:59, 24.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Checkpoint] Saved eval progress at idx=1090000 -> /content/drive/MyDrive/labtop2/v1/eval_progress.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating:  50%|█████     | 130003/259791 [58:06<1:39:25, 21.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Checkpoint] Saved eval progress at idx=1100000 -> /content/drive/MyDrive/labtop2/v1/eval_progress.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating:  54%|█████▍    | 140008/259791 [1:02:33<1:20:24, 24.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Checkpoint] Saved eval progress at idx=1110000 -> /content/drive/MyDrive/labtop2/v1/eval_progress.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating:  58%|█████▊    | 150006/259791 [1:07:01<1:02:25, 29.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Checkpoint] Saved eval progress at idx=1120000 -> /content/drive/MyDrive/labtop2/v1/eval_progress.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating:  62%|██████▏   | 160004/259791 [1:11:30<1:10:20, 23.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Checkpoint] Saved eval progress at idx=1130000 -> /content/drive/MyDrive/labtop2/v1/eval_progress.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating:  65%|██████▌   | 170007/259791 [1:15:56<58:41, 25.50it/s]  "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Checkpoint] Saved eval progress at idx=1140000 -> /content/drive/MyDrive/labtop2/v1/eval_progress.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating:  69%|██████▉   | 180005/259791 [1:20:23<52:26, 25.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Checkpoint] Saved eval progress at idx=1150000 -> /content/drive/MyDrive/labtop2/v1/eval_progress.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating:  73%|███████▎  | 190005/259791 [1:24:49<45:12, 25.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Checkpoint] Saved eval progress at idx=1160000 -> /content/drive/MyDrive/labtop2/v1/eval_progress.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating:  77%|███████▋  | 200005/259791 [1:29:15<38:27, 25.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Checkpoint] Saved eval progress at idx=1170000 -> /content/drive/MyDrive/labtop2/v1/eval_progress.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating:  81%|████████  | 210007/259791 [1:33:39<31:17, 26.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Checkpoint] Saved eval progress at idx=1180000 -> /content/drive/MyDrive/labtop2/v1/eval_progress.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating:  85%|████████▍ | 220006/259791 [1:38:04<27:33, 24.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Checkpoint] Saved eval progress at idx=1190000 -> /content/drive/MyDrive/labtop2/v1/eval_progress.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating:  89%|████████▊ | 230006/259791 [1:42:33<20:38, 24.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Checkpoint] Saved eval progress at idx=1200000 -> /content/drive/MyDrive/labtop2/v1/eval_progress.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating:  92%|█████████▏| 240006/259791 [1:47:00<13:52, 23.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Checkpoint] Saved eval progress at idx=1210000 -> /content/drive/MyDrive/labtop2/v1/eval_progress.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating:  96%|█████████▌| 250004/259791 [1:51:27<07:03, 23.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Checkpoint] Saved eval progress at idx=1220000 -> /content/drive/MyDrive/labtop2/v1/eval_progress.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 259791/259791 [1:55:49<00:00, 37.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Removed eval progress file /content/drive/MyDrive/labtop2/v1/eval_progress.pkl\n",
            "\n",
            "Evaluated 1229124 samples in 6950.21 seconds.\n",
            "Test MAE:   35.0470\n",
            "Test RMSE:  1321.8479\n",
            "Test NMAE:  0.0767\n",
            "Test SMAPE: 0.2935\n",
            "Saving predictions to: /content/drive/MyDrive/labtop2/v1/test_predictions.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch, os\n",
        "\n",
        "path = \"/content/drive/MyDrive/labtop2/v1/labtop_v1.pth\"  # 改成你想查的\n",
        "state = torch.load(path, map_location=\"cpu\")\n",
        "print(state.keys())\n",
        "\n",
        "ckpt = torch.load(path, map_location=\"cpu\")\n",
        "wte = ckpt[\"model.transformer.wte.weight\"]\n",
        "wpe = ckpt[\"model.transformer.wpe.weight\"]\n",
        "\n",
        "print(\"wte shape:\", wte.shape)  # (vocab_size, d_model)\n",
        "print(\"wpe shape:\", wpe.shape)  # (max_positions, d_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lbLLc2iXyYKr",
        "outputId": "13cfefd7-d9dd-45b7-d540-ad9bc1800591"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "odict_keys(['model.transformer.wte.weight', 'model.transformer.wpe.weight', 'model.transformer.h.0.ln_1.weight', 'model.transformer.h.0.ln_1.bias', 'model.transformer.h.0.attn.c_attn.weight', 'model.transformer.h.0.attn.c_attn.bias', 'model.transformer.h.0.attn.c_proj.weight', 'model.transformer.h.0.attn.c_proj.bias', 'model.transformer.h.0.ln_2.weight', 'model.transformer.h.0.ln_2.bias', 'model.transformer.h.0.mlp.c_fc.weight', 'model.transformer.h.0.mlp.c_fc.bias', 'model.transformer.h.0.mlp.c_proj.weight', 'model.transformer.h.0.mlp.c_proj.bias', 'model.transformer.h.1.ln_1.weight', 'model.transformer.h.1.ln_1.bias', 'model.transformer.h.1.attn.c_attn.weight', 'model.transformer.h.1.attn.c_attn.bias', 'model.transformer.h.1.attn.c_proj.weight', 'model.transformer.h.1.attn.c_proj.bias', 'model.transformer.h.1.ln_2.weight', 'model.transformer.h.1.ln_2.bias', 'model.transformer.h.1.mlp.c_fc.weight', 'model.transformer.h.1.mlp.c_fc.bias', 'model.transformer.h.1.mlp.c_proj.weight', 'model.transformer.h.1.mlp.c_proj.bias', 'model.transformer.h.2.ln_1.weight', 'model.transformer.h.2.ln_1.bias', 'model.transformer.h.2.attn.c_attn.weight', 'model.transformer.h.2.attn.c_attn.bias', 'model.transformer.h.2.attn.c_proj.weight', 'model.transformer.h.2.attn.c_proj.bias', 'model.transformer.h.2.ln_2.weight', 'model.transformer.h.2.ln_2.bias', 'model.transformer.h.2.mlp.c_fc.weight', 'model.transformer.h.2.mlp.c_fc.bias', 'model.transformer.h.2.mlp.c_proj.weight', 'model.transformer.h.2.mlp.c_proj.bias', 'model.transformer.h.3.ln_1.weight', 'model.transformer.h.3.ln_1.bias', 'model.transformer.h.3.attn.c_attn.weight', 'model.transformer.h.3.attn.c_attn.bias', 'model.transformer.h.3.attn.c_proj.weight', 'model.transformer.h.3.attn.c_proj.bias', 'model.transformer.h.3.ln_2.weight', 'model.transformer.h.3.ln_2.bias', 'model.transformer.h.3.mlp.c_fc.weight', 'model.transformer.h.3.mlp.c_fc.bias', 'model.transformer.h.3.mlp.c_proj.weight', 'model.transformer.h.3.mlp.c_proj.bias', 'model.transformer.ln_f.weight', 'model.transformer.ln_f.bias', 'model.lm_head.weight'])\n",
            "wte shape: torch.Size([29043, 256])\n",
            "wpe shape: torch.Size([1024, 256])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pickle\n",
        "from collections import Counter\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "OUT_DIR = \"/content/drive/MyDrive/labtop2/v1\"\n",
        "\n",
        "def load_pkl(name):\n",
        "    with open(os.path.join(OUT_DIR, name), \"rb\") as f:\n",
        "        return pickle.load(f)\n",
        "\n",
        "# 1. 看一下有哪些 pkl，大小\n",
        "# for fn in os.listdir(OUT_DIR):\n",
        "#     if fn.endswith(\".pkl\"):\n",
        "#         path = os.path.join(OUT_DIR, fn)\n",
        "#         print(fn, os.path.getsize(path) / 1024 / 1024, \"MB\")\n",
        "\n",
        "# 2. 读一小段 train / val\n",
        "train = load_pkl(\"train.pkl\")[:200]\n",
        "val   = load_pkl(\"val.pkl\")[:200]\n",
        "\n",
        "print(\"sample train size:\", len(train))\n",
        "\n",
        "# 3. 检查每条的 keys、长度、type_ids 分布\n",
        "print(\"keys in one example:\", train[0].keys())\n",
        "print(\"len(input_ids):\", len(train[0][\"input_ids\"]))\n",
        "print(\"len(type_ids):\", len(train[0][\"type_ids\"]))\n",
        "\n",
        "from collections import Counter\n",
        "c = Counter()\n",
        "for x in train:\n",
        "    c.update(x[\"type_ids\"])\n",
        "print(\"type_ids counts:\", dict(c))\n",
        "\n",
        "# 4. 解码几条看看文本大概长什么样\n",
        "tok = AutoTokenizer.from_pretrained(OUT_DIR)\n",
        "for i in range(3):\n",
        "    ids = train[i][\"input_ids\"][:300]\n",
        "    print(f\"\\n=== train sample {i} ===\")\n",
        "    print(tok.decode(ids))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X2EKSzSAPkPU",
        "outputId": "107706c7-051f-4d6d-e07e-cedfe1dc6fb4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sample train size: 200\n",
            "keys in one example: dict_keys(['stay_id', 'input_ids', 'type_ids'])\n",
            "len(input_ids): 276\n",
            "len(type_ids): 276\n",
            "type_ids counts: {0: 147166, 1: 36570}\n",
            "\n",
            "=== train sample 0 ===\n",
            "gender f age 52 race white [DAY0] [SUN] [00h] [20m] procedureevent 18 gauge 5 6 6 min [EOE] [DAY0] [SUN] [00h] [20m] procedureevent 20 gauge 5 6 6 min [EOE] [DAY0] [SUN] [01h] [00m] outputevent void 1 7 5 ml [EOE] [DAY0] [SUN] [03h] [00m] inputevent albumin 25 % 5 0 ml [EOE] [DAY0] [SUN] [03h] [00m] inputevent po intake 2 0 0 ml [EOE] [DAY0] [SUN] [03h] [30m] inputevent albumin 25 % 5 0 ml [EOE] [DAY0] [SUN] [04h] [50m] inputevent po intake 1 0 0 ml [EOE] [DAY0] [SUN] [07h] [10m] inputevent po intake 1 0 0 ml [EOE] [DAY0] [SUN] [07h] [40m] labevent urea nitrogen 3 3 mg / dl [EOE] [DAY0] [SUN] [07h] [40m] labevent anion gap 1 4 meq / l [EOE] [DAY0] [SUN] [07h] [40m] labevent phosphate 2. 4 mg / dl [EOE] [DAY0] [SUN] [07h] [40m] labevent magnesium 2. 3 mg / dl [EOE] [DAY0] [SUN] [07h] [40m] labevent glucose 1 1 5 mg / dl [EOE] [DAY0] [SUN] [07h] [40m] labevent creatinine 0. 5 mg / dl [EOE] [DAY0] [SUN] [07h] [40m] labevent chloride 1 0 2 meq / l [EOE] [DAY0] [SUN] [07h] [40m] labevent calcium, total 9. 3 mg / dl [EOE] [DAY0] [SUN] [07h] [40m] labevent bicarbonate 2 1 meq / l [EOE] [DAY0] [SUN] [07h] [40m] labevent potassium 4. 7 meq / l [EOE] [DAY0] [SUN] [07h] [40m] labevent sodium 1 3 2 meq / l [EOE]\n",
            "\n",
            "=== train sample 1 ===\n",
            "gender f age 86 race white [DAY0] [MON] [00h] [20m] inputevent phenylephrine 5. 4 8 mg [EOE] [DAY0] [MON] [00h] [20m] procedureevent 20 gauge 1 0 2 0 min [EOE] [DAY0] [MON] [00h] [20m] inputevent nacl 0. 9 % 2 2. 8 2 ml [EOE] [DAY0] [MON] [01h] [00m] procedureevent 18 gauge 9 2 1 min [EOE] [DAY0] [MON] [01h] [50m] outputevent foley 8 0 ml [EOE] [DAY0] [MON] [02h] [20m] outputevent foley 3 0 ml [EOE] [DAY0] [MON] [03h] [00m] inputevent nacl 0. 9 % 5. 8 8 ml [EOE] [DAY0] [MON] [03h] [00m] inputevent phenylephrine 1. 4 1 mg [EOE] [DAY0] [MON] [03h] [20m] outputevent foley 6 0 ml [EOE] [DAY0] [MON] [03h] [50m] inputevent phenylephrine 1. 3 1 mg [EOE] [DAY0] [MON] [03h] [50m] inputevent nacl 0. 9 % 5. 4 4 ml [EOE] [DAY0] [TUE] [04h] [20m] outputevent foley 5 0 ml [EOE] [DAY0] [TUE] [04h] [50m] inputevent phenylephrine 0. 5 3 mg [EOE] [DAY0] [TUE] [04h] [50m] inputevent nacl 0. 9 % 2. 2 1 ml [EOE] [DAY0] [TUE] [05h] [20m] outputevent foley 4 0 ml [EOE] [DAY0] [TUE] [05h] [30m] inputevent phenylephrine 0. 6 2 mg [EOE] [DAY0] [TUE] [05h] [30m] inputevent nacl 0. 9 % 2. 5 8 ml [EOE] [DAY0] [TUE] [06h] [20m] outputevent foley 2 0 ml [EOE] [DAY0] [TUE] [07h] [10m] labevent urea nitrogen 2 1 mg / dl [EOE]\n",
            "\n",
            "=== train sample 2 ===\n",
            "gender f age 86 race white [DAY1] [WED] [04h] [20m] outputevent foley 4 5 ml [EOE] [DAY1] [WED] [05h] [20m] outputevent foley 3 0 ml [EOE] [DAY1] [WED] [06h] [20m] outputevent foley 4 5 ml [EOE] [DAY1] [WED] [07h] [20m] outputevent foley 3 5 ml [EOE] [DAY1] [WED] [07h] [20m] labevent anion gap 1 1 meq / l [EOE] [DAY1] [WED] [07h] [20m] labevent red blood cells 3. 2 1 m / ul [EOE] [DAY1] [WED] [07h] [20m] labevent white blood cells 6. 1 k / ul [EOE] [DAY1] [WED] [07h] [20m] labevent mcv 9 6 fl [EOE] [DAY1] [WED] [07h] [20m] labevent rdw 1 6. 4 % [EOE] [DAY1] [WED] [07h] [20m] labevent bicarbonate 2 6 meq / l [EOE] [DAY1] [WED] [07h] [20m] labevent mchc 3 2. 4 % [EOE] [DAY1] [WED] [07h] [20m] labevent hematocrit 3 0. 7 % [EOE] [DAY1] [WED] [07h] [20m] labevent hemoglobin 1 0 g / dl [EOE] [DAY1] [WED] [07h] [20m] labevent platelet count 1 9 4 k / ul [EOE] [DAY1] [WED] [07h] [20m] labevent urea nitrogen 2 5 mg / dl [EOE] [DAY1] [WED] [07h] [20m] labevent sodium 1 3 4 meq / l [EOE] [DAY1] [WED] [07h] [20m] labevent potassium 4. 7 meq / l [EOE] [DAY1] [WED] [07h] [20m] labevent phosphate 3. 7 mg / dl [EOE] [DAY1] [WED] [07h] [20m] labevent magnesium 2 mg / dl [EOE] [DAY1] [WED] [07h] [20m] labevent glucose 8 4 mg / dl [EOE] [DAY1] [WED] [07h] [20m] labevent creatinine 0.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eDZwV7XkRBRW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}